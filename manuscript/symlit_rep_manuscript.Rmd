---
title             : "Young children’s Spontaneous Comprehension of Various Symbol-Referent Relationships in the Graphic Domain"
shorttitle        : "Children's Comprehension of Symbol-Referent Relationships"
author: 
  - name          : "Gregor Kachel"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Universitätsallee 1, C1.008a, 21335 Lüneburg"
    email         : "gregor.kachel&#64;leuphana.de"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Funding Acquisition"
      - "Project Administration"
      - "Investigation"
      - "Methodology"
      - "Data Curation"
      - "Formal Analysis"
      - "Visualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Daniel Haun"
    affiliation   : "2"
    role:
      - "Resources"
      - "Writing - Review & Editing"
  - name          : "Manuel Bohn"
    affiliation   : "1"
    role:
      - "Methodology"
      - "Software"
      - "Formal Analysis"
      - "Validation"
      - "Writing - Review & Editing"
      - "Supervision"
affiliation:
  - id            : "1"
    institution   : "Leuphana University"
  - id            : "2"
    institution   : "Max-Planck-Institute for Evolutionary Anthropology"
note: "\\clearpage"
authornote: |
    
    
    *Ethics, consent and conflict of interest*: This study confirms with recognized standards (e.g. the Declaration of Helsinki) and was approved by an internal ethics committee at the Max-Planck-Institute for Evolutionary Anthropology. Informed consent has been obtained from all participants. The authors declare no conflict of interest. 
    *Scientific Integrity and Openness*: The data and code necessary to reproduce the analyses presented here are publicly accessible, as are the materials necessary to attempt to replicate the findings. Analyses were also pre-registered. Data, code, materials, and the preregistration for this research are available at the following URL XXX Repo XXX.
    *Acknowledgments*: We are thankful to Susanne Mauritz for her help in the organization of the study and to Valerie Jurgenson and Cynthia Pones for help with data collection. We would like to thank Anne Deiglmayr for hosting this project in her research group and for her continuous support. Finally, we are very thankful to all parents and children participating in the study. Gregor Kachel was supported by the German Research Foundation (Deutsche Forschungsgemeinschaft) under project number 429220405.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  One or two sentences to put the results into a more **general context**.
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline. Abstract must be less then 120words
  
  
  <!-- https://tinyurl.com/ybremelq -->
keywords          : "Graphic Communication, Iconicity, Analogical Reasoning, Gestalt Principles, Pragmatics, Emerging Literacy, Symbolic Literacy, Symbol-Referent-Relationship"
wordcount         : "Child Development Max 40 pages // PNAS 1,500–2,000 words"
bibliography      : ["library.bib"]
floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
output:
  papaja::apa6_doc: default
    
appendix: # to change filenames, also see end of document
- "appendix_a_participants.Rmd"
- "appendix_b_stimuli.Rmd"
- "appendix_c_descriptives.Rmd"
- "appendix_d_diagnostics.Rmd"
- "appendix_e_additional.Rmd"
editor_options: 
  markdown: 
    wrap: 72
---

<!-- Packages, Setup, Read data for all studies, and prepare for analyses -->

```{r setup, include = FALSE}
library("papaja")
r_refs("library.bib")

# NOTE; how to push title, authornotes and abstract 
# note: "\\clearpage"


# Loading packages 
# NOTE: this will install these packages in case they are missing

# General
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
if (!require(lsr)) install.packages('lsr'); library(lsr) # Analysis, Cohen's D
if (!require(ggthemes)) install.packages('ggthemes'); library(ggthemes) # for tufte boxplots
# if (!require(kableExtra)) install.packages('kableExtra'); library(kableExtra) 

library(cowplot)
library(magick)

# Styling library(flextable)
if (!require(flextable)) install.packages('flextable'); library(flextable) 

# bayes packages
if (!require(brms)) install.packages('brms'); library(brms) # 
if (!require(tidybayes)) install.packages('tidybayes'); library(tidybayes) # 
if (!require(HDInterval)) install.packages('HDInterval'); library(HDInterval) # 
if (!require(posterior)) install.packages('posterior'); library(posterior) # 

# basic analyses
if (!require(scales)) install.packages('scales'); library(scales) # 

# plotting
## ggplot via tidyverse
if (!require(cowplot)) install.packages('cowplot'); library(cowplot) # 
if (!require(png)) install.packages('png'); library(png) # 
if (!require(grid)) install.packages('grid'); library(grid) # 

# Troubleshooting Knitting Document
# might be required for knitting manuscript
# install.packages('tinytex')
# tinytex::install_tinytex()
# 
# tinytex::tlmgr_update()
# tinytex::reinstall_tinytex()

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)


```

```{r rep_read_data, include = FALSE}

# Full data set including all participants (i.e. including dropped participants)
rep.data <- readRDS("../data/symlitrep_final_data.rds")

# test  <- rep.data %>%
#   #filter(valid != "drop") %>% # valid participants only 
#   filter(trial != "fam") %>% 
#   group_by(subid, agem) %>% 
#   summarize(participants = n_distinct(subid),
#             trials = n())

# Study1 
rep.S1.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study1") %>% # in study one
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Representation", # first level becomes reference
        "Pars Pro Toto", 
        "Simple Form Analogy", 
        "Complex Form Analogy"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# Study2
rep.S2.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study2") %>% # in study two
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Absolute Position", # first level becomes reference
        "Relative Position", 
        "Orientation of Object", 
        "Orientation of Feature"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# Study 3 
rep.S3.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study3") %>% # in study two
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Size of Object", # first level becomes reference
        "Size of Feature", 
        "Number of Object", 
        "Number of Feature"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# test <- rep.data %>%
#   filter(valid != "drop") %>%
#   group_by(study) %>%
#   summarize(min_Age = min(agem))

# test <- rep.data %>% 
#   filter(valid != "drop") %>% 
#   group_by(study, condition) %>% 
#   summarize(N = length(subid))


```

```{r S1S2s3_colours, echo=FALSE, eval=T}
#
add_colour <- function(df) {
  df %>%
    mutate(colour = case_when(
      condition == "Representation" ~ "#00441b",
      condition == "Pars Pro Toto" ~ "#238b45",
      condition == "Simple Form Analogy" ~ "#cc4c02",
      condition == "Complex Form Analogy" ~ "#ff9609",
      condition == "Absolute Position" ~ "#084081",
      condition == "Relative Position" ~ "#2b8cbe",
      condition == "Orientation of Object" ~ "#7B3F00",
      condition == "Orientation of Feature" ~ "#B55239",
      condition == "Size of Object" ~ "#2E004F", 
      condition == "Size of Feature" ~ "#9370DB",
      condition == "Number of Object" ~ "#67000d",
      condition == "Number of Feature" ~ "#cb181d",
      TRUE ~ NA_character_
    ))
}

# condition_colours_df <- data.frame(
#   condition = c(
#     # study1
#     "Representation", 
#     "Pars Pro Toto", 
#     "Simple Form Analogy", 
#     "Complex Form Analogy",
#     # study 2
#     "Absolute Position", 
#     "Relative Position", 
#     "Orientation of Object", 
#     "Orientation of Feature",
#     # study3
#     "Size of Object", 
#     "Size of Feature",
#     "Number of Object", 
#     "Number of Feature"),
#   colour = c(
#     # study1
#     "#006400", "#79e000", "#ff9609", "#ffc512",
#     # study2
#     "#4B0082", "#6A5ACD", "#8B0000", "#A0522D",
#     # study3
#     "#191970", "#008080", "#800080", "#8B008B"
#   ),
#   stringsAsFactors = F
# )
# 
# # Function to add colour using left_join
# add_colour <- function(df) {
#   df %>% 
#     left_join(condition_colours_df, by = "condition")
# }

# condition_colours <- c(
#   "Representation" = "#006400",  # Dark Green
#   "Pars Pro Toto" = "#79e000",    # Forest Green
#   "Simple Form Analogy" = "#ff9609",  
#   "Complex Form Analogy" = "#ffc512", 
#   "Absolute Position" = "#4B0082",    # Indigo (dark purple)
#   "Relative Position" = "#6A5ACD",    # Slate Blue
#   "Orientation of Object" = "#8B0000", # Dark Red
#   "Orientation of Feature" = "#A0522D", # Sienna (dark orange-brown)
#   "Size of Object" = "#191970",        # Midnight Blue
#   "Size of Feature" = "#008080",       # Teal
#   "Number of Object" = "#800080",      # Purple
#   "Number of Feature" = "#8B008B"       # Dark Magenta
# )

```

<!-- Prepare Demographics -->

```{r S1S2s3_participant_demographics, echo=F, eval=T}

rep.age.table.data  <- rep.data %>% 
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid != "drop") %>%  # filter out dropped participants
  group_by(study) %>% 
  summarize(
    N = length(subid),
    female = sum(sex=="0"),
    Mean = mean(agem),
    Min = min(agem),
    Max = max(agem),
    SD = round(sd(agem), 2),
    N_daycare = length(subid[where == "daycare"]),
    N_lab = length(subid[where == "lab"]),
    N_home = length(subid[where == "home"]),
    N_hort = length(subid[where == "afterschoolcenter"]))

rep.age.table.data <- data.frame(rep.age.table.data, row.names = "study")

rep.drop.table.data  <- rep.data %>%
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid == "drop") %>%
  group_by(study) %>%
  summarize(
    N = length(subid),
    female = sum(sex=="0"),
    Mean = mean(agem),
    Min = min(agem),
    Max = max(agem),
    fail_in_fam = length(subid[drop == "fail_in_fam"]),
    quit_early = length(subid[drop == "quit_early"]),
    fussy_child = length(subid[drop == "fussy_child"]),
    language = length(subid[drop == "language"]),
    technical = length(subid[drop == "technical"]))

rep.drop.table.data <- data.frame(rep.drop.table.data, row.names = "study")

# Count trials by conditions
rep.s1.trials <- rep.S1.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

rep.s2.trials <- rep.S2.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

rep.s3.trials <- rep.S3.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

```

```{r plot-participants-dots, echo = F, warning=F}

age.plot.data <- rep.data %>% #select data
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid != "drop")  %>%
  mutate(sex = as.factor(sex))  %>%
  mutate(sex = fct_recode(sex, "female" = "0","male"="1")) %>% 
  rename(Sex = sex) %>% 
  mutate(study = case_when(
    study == "study1" ~ "Study 1",
    study == "study2" ~ "Study 2",
    study == "study3" ~ "Study 3",
    TRUE ~ NA_character_))

age.plot <- ggplot(age.plot.data, aes(x = agem, fill = Sex)) +
  geom_dotplot(stackgroups = TRUE, binwidth = 1, binpositions = "all") +  
  coord_fixed(ratio = 4, xlim = c(36, 84), ylim = c(0, 1.01)) +  # combine here
  theme_bw() +
  scale_x_continuous(name = "Age in Months", breaks = seq(36, 84, 12), minor_breaks = seq(36, 84, 1)) +
  scale_y_continuous(name = "Participants", breaks = NULL) +
  facet_wrap(~ study, ncol = 1) +
  labs(fill = NULL) +
  guides(fill = guide_legend(ncol =2, byrow = TRUE)) +  
  theme_minimal() +
  theme(
    base_size = 13,
    panel.grid.minor.x = element_line(linewidth = 0.25, linetype = 2),
    panel.grid.major.x = element_line(linewidth = 1, linetype = 1),
    panel.border = element_rect(colour = "grey30", fill = NA, linewidth = 1),
    strip.background = element_rect(colour = "grey30", size = 1),
    strip.text = element_text(face = "bold", size = rel(.9), 
                              margin = margin(t = 5, b = 8)),
    axis.title = element_text(face = "bold", size = rel(.9)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = c(1, -0.06),              
    legend.justification = c(1, 1),
    legend.text = element_text(size = rel(.9)),
    panel.grid.minor = element_blank()
  )

ggsave(
  filename = "../illustrations/plot_supp_participants_S123.png",
  plot = age.plot,
  device = "png",
  width = 9.5, height = 6,
  dpi = 300,
  units = "in",
  bg = "white")
# 
# # display plot
# img <- image_read("../illustrations/plot_participants_S123.png")
# 
# windows(width = 15, height = 10)  # On Windows
# plot(img)



```

```{r plot-exclusions-dots, echo = F, warning=F}

drop.plot.data <- rep.data %>% #select data
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid == "drop") %>% 
  mutate(study = case_when(
    study == "study1" ~ "Study 1",
    study == "study2" ~ "Study 2",
    study == "study3" ~ "Study 3",
    TRUE ~ NA_character_)) %>% 
  mutate(drop = case_when(
    drop == "fail_in_fam" ~ "< 75% Correct in Familiarization",
    drop == "fussy_child" ~ "Fussy Child", 
    drop == "language" ~ "Low Language Proficiency", 
    drop == "quit_early" ~ "Quit Early",
    drop == "technical" ~ "Technical Problem",
    TRUE ~ NA_character_)) %>%  
  mutate(drop = factor(drop, levels = c(
    "< 75% Correct in Familiarization",
    "Quit Early",
    "Fussy Child",
    "Low Language Proficiency",
    "Technical Problem")))

drop.plot <- ggplot(drop.plot.data, aes(x = agem, fill = drop)) +
  geom_dotplot(stackgroups = TRUE, binwidth = 1, binpositions = "all") +  
  theme_bw() +
  scale_x_continuous(name = "Age in Months", breaks = seq(36, 84, 12), minor_breaks = seq(36, 84, 1)) +
  scale_y_continuous(name = "Exclusions", breaks = NULL) +
  coord_fixed(ratio = 4, xlim = c(36, 84), ylim = c(0, 1.5)) + 
  facet_wrap(~ study, ncol = 1) +
  labs(fill = NULL) +
  guides(fill = guide_legend(ncol = 5, byrow = TRUE)) +  
  theme_minimal(base_size = 13) +
  theme(
    panel.grid.minor.x = element_line(linewidth = 0.25, linetype = 2),
    panel.grid.major.x = element_line(linewidth = 1, linetype = 1),
    panel.border = element_rect(colour = "grey30", fill = NA, linewidth = 1),
    strip.background = element_rect(colour = "grey30", size = 1),
    strip.text = element_text(face = "bold", size = rel(.9), 
                              margin = margin(t = 5, b = 8)),
    axis.title = element_text(face = "bold", size = rel(.9)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = "bottom",
    legend.justification = c(1, 1),
    legend.text = element_text(size = rel(.9)),
    legend.margin = margin(t = 2),
    plot.margin = margin(10, 10, 10, 10),
    panel.grid.minor = element_blank()
  )

ggsave(
  filename = "../illustrations/plot_supp_exclusions_S123.png",
  plot = drop.plot,
  device = "png",
  width = 9.5, height = 6,
  dpi = 300,
  units = "in",
  bg = "white")


# # display plot
# img <- image_read("../illustrations/plot_supp_exclusions_S123.png")
# 
# windows(width = 15, height = 10)  # On Windows
# plot(img)

```

<!-- Run full and null models for all three studies (not evaluated to save time) -->

```{r rep_s1_bayes, echo = FALSE, include=F, eval=F, results='asis'}

# NOTE: this is section is not evaluated to save time during knitting

# in prergistration we used the term "task" instead of "condition", same thing
# we have now decided to not scale sex to make interpretation more straightforward
# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S1.full.bm<-brm(correct~condition*z.age+z.trial+sex+(z.trial|subid), 
               data= rep.S1.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S1.full.bm <- add_criterion(S1.full.bm, c("loo", "waic"))

S1.null.bm<-brm(correct~condition+z.age+z.trial+sex+(z.trial|subid), 
               data= rep.S1.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S1.null.bm <- add_criterion(S1.null.bm, c("loo", "waic"))

### MODEL COMPARISON
S1.comp <- loo_compare(S1.null.bm, S1.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S1.comp <- data.frame(S1.comp, row.names = "index")

S1.weights <- model_weights(S1.null.bm, S1.full.bm, criterion = "waic") 
S1.weights <- S1.weights %>% as_tibble(rownames = "index")
S1.weights <- data.frame(S1.weights, row.names = "index")

# "significant" if elpd_diff > 2*se_diff (confer Sivula et al., 2020)

### LOO COMPARISON
### not reported, essentially identical
# S1.null.loo <- loo(S1.null.bm)
# S1.full.loo <- loo(S1.full.bm)
# S1.loo.comp <- loo_compare(S1.null.loo, S1.full.loo) %>%
#   as_tibble(rownames = "model")
# S1.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S1.full.bm, "../models/S1.full.bm.rds")
saveRDS(S1.null.bm, "../models/S1.null.bm.rds")
saveRDS(S1.comp, "../models/S1.comp.rds")
saveRDS(S1.weights, "../models/S1.weights.rds")

### item level model
# S1.item.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid)+ (z.age|item), 
#                data= rep.S1.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)


```

```{r rep_s2_bayes, echo = FALSE, include=F, eval=F, results='asis'}

# NOTE: this is section is not evaluated to save time during knitting

# in prergistration we used the term "task" instead of "condition", same thing
# we have now decided to not scale sex to make interpretation more straightforward
# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S2.full.bm<-brm(correct~condition*z.age+z.trial+sex+(z.trial|subid), 
                data= rep.S2.bayes.data, 
                family=bernoulli(),
                chains = 4,
                iter= 5000,
                cores= 4)

S2.full.bm <- add_criterion(S2.full.bm, c("loo", "waic"))

S2.null.bm<-brm(correct~condition+z.age+z.trial+sex+(z.trial|subid), 
                data= rep.S2.bayes.data, 
                family=bernoulli(),
                chains = 4,
                iter= 5000,
                cores= 4)

S2.null.bm <- add_criterion(S2.null.bm, c("loo", "waic"))

### MODEL COMPARISON
S2.comp <- loo_compare(S2.null.bm, S2.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S2.comp <- data.frame(S2.comp, row.names = "index")


S2.weights <- model_weights(S2.null.bm, S2.full.bm, criterion = "waic") 
S2.weights <- S2.weights %>% as_tibble(rownames = "index")
S2.weights <- data.frame(S2.weights, row.names = "index")


# "significant" if elpd_diff > 2*se_diff (confer Sivula et al., 2020)

### LOO COMPARISON
### not reported, essentially identical
# S2.null.loo <- loo(S2.null.bm)
# S2.full.loo <- loo(S2.full.bm)
# S2.loo.comp <- loo_compare(S2.null.loo, S2.full.loo) %>%
#   as_tibble(rownames = "model")
# S2.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S2.full.bm, "../models/S2.full.bm.rds")
saveRDS(S2.null.bm, "../models/S2.null.bm.rds")
saveRDS(S2.comp, "../models/S2.comp.rds")
saveRDS(S2.weights, "../models/S2.weights.rds")

### item level model
# S2.item.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid)+ (z.age|item), 
#                data= rep.S2.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)

```

```{r rep_s3_bayes, echo = FALSE, include=F, eval=F, results='asis'}



# NOTE: this is section is not evaluated to save time during knitting

# in prergistration we used the term "task" instead of "condition", same thing
# we have now decided to not scale sex to make interpretation more straightforward
# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S3.full.bm<-brm(correct~condition*z.age+z.trial+sex+(z.trial|subid), 
                data= rep.S3.bayes.data, 
                family=bernoulli(),
                chains = 4,
                iter= 5000,
                cores= 4)

S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))

S3.null.bm<-brm(correct~condition+z.age+z.trial+sex+(z.trial|subid), 
                data= rep.S3.bayes.data, 
                family=bernoulli(),
                chains = 4,
                iter= 5000,
                cores= 4)

S3.null.bm <- add_criterion(S3.null.bm, c("loo", "waic"))

### MODEL COMPARISON
S3.comp <- loo_compare(S3.null.bm, S3.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S3.comp <- data.frame(S3.comp, row.names = "index")


S3.weights <- model_weights(S3.null.bm, S3.full.bm, criterion = "waic") 
S3.weights <- S3.weights %>% as_tibble(rownames = "index")
S3.weights <- data.frame(S3.weights, row.names = "index")




# "significant" if elpd_diff > 2*se_diff (confer Sivula et al., 2020)

### LOO COMPARISON
### not reported, essentially identical
# S3.null.loo <- loo(S3.null.bm)
# S3.full.loo <- loo(S3.full.bm)
# S3.loo.comp <- loo_compare(S3.null.loo, S3.full.loo) %>%
#   as_tibble(rownames = "model")
# S3.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S3.full.bm, "../models/S3.full.bm.rds")
saveRDS(S3.null.bm, "../models/S3.null.bm.rds")
saveRDS(S3.comp, "../models/S3.comp.rds")
saveRDS(S3.weights, "../models/S3.weights.rds")

### item level model
# S3.item.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid)+ (z.age|item), 
#                data= rep.S3.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)




```

<!-- Diagnostics for all three studies -->

```{r rep_s1_inspect, echo = FALSE, include=F, eval=T, results='asis'}

S1.full.bm <- readRDS("../models/S1.full.bm.rds")
S1.null.bm <- readRDS("../models/S1.null.bm.rds")

S1.comp <- readRDS("../models/S1.comp.rds")
S1.weights <- readRDS("../models/S1.weights.rds")

### POSTERIOR PREDICTICE CHECKS
### Check plots ...they look good, as expected in binomial models
# pp_check(S1.full.bm)
# pp_check(S1.null.bm)
# pp_check(S1.full.bm, type = "bars")
# pp_check(S1.null.bm, type = "bars")

### EFFECTICE SAMPLE SIZES
### inspect rhat --> always 1 --> good
### inspect Bull_ESS --> always > 1000 --> good
# summary(S1.full.bm)
# summary(S1.null.bm)

# for reporting BULK_ESS and Coefficients
S1.full.coef <- summarise_draws(as_draws_df(S1.full.bm)) # ! standard is just 90% CrI

# NOTE: # as_draws_df() from posterior uses 90% CrIs
# we preregistered using 2.5% and 97.5% quantiles
draws_df <- as_draws_df(S1.full.bm)
quantiles_df <- as.data.frame(t(apply(draws_df, 2, quantile, probs = c(0.025, 0.975))))
quantiles_df <- tibble::rownames_to_column(quantiles_df, var = "variable")
names(quantiles_df)[2:3] <- c("q2.5", "q97.5")

S1.full.coef <- left_join(S1.full.coef, quantiles_df, by = "variable") 

# for table in appendix:
S1.full.coef.table <- S1.full.coef

# for reporting in text:
S1.full.coef <- S1.full.coef %>% 
  filter(grepl("^b_", variable)) %>% 
  mutate(variable = gsub("b_", "", variable)) %>% 
  mutate(variable = gsub("condition", "", variable)) %>% 
  data.frame(row.names = "variable")

S1.null.coef <- summarise_draws(as_draws_df(S1.null.bm)) %>%
  filter(grepl("^b_", variable))
# 
# mean(S1.full.coef$ess_bulk)
# min(S1.full.coef$ess_bulk)
# max(S1.full.coef$ess_bulk)
# 
# mean(S1.null.coef$ess_bulk)
# min(S1.null.coef$ess_bulk)
# max(S1.null.coef$ess_bulk)


```

```{r rep_s2_inspect, echo = FALSE, include=F, eval=T, results='asis'}

S2.full.bm <- readRDS("../models/S2.full.bm.rds")
S2.null.bm <- readRDS("../models/S2.null.bm.rds")

S2.comp <- readRDS("../models/S2.comp.rds")
S2.weights <- readRDS("../models/S2.weights.rds")


### POSTERIOR PREDICTICE CHECKS
### Check plots ...they look good, as expected in binomial models
# pp_check(S2.full.bm)
# pp_check(S2.null.bm)
# pp_check(S2.full.bm, type = "bars")
# pp_check(S2.null.bm, type = "bars")

### EFFECTICE SAMPLE SIZES
### inspect rhat --> always 1 --> good
### inspect Bull_ESS --> always > 1000 --> good
# summary(S2.full.bm)
# summary(S2.null.bm)

# # for reporting BULK_ESS
# S2.full.coef <- summarise_draws(as_draws_df(S2.full.bm)) %>%
#   filter(grepl("^b_", variable)) %>% 
#   mutate(variable = gsub("b_", "", variable)) %>% 
#   mutate(variable = gsub("condition", "", variable)) %>% 
#   data.frame(row.names = "variable")

# for reporting BULK_ESS and Coefficients
S2.full.coef <- summarise_draws(as_draws_df(S2.full.bm)) # ! standard is just 90% CrI

# NOTE: # as_draws_df() from posterior uses 90% CrIs
# we preregistered using 2.5% and 97.5% quantiles
draws_df <- as_draws_df(S2.full.bm)
quantiles_df <- as.data.frame(t(apply(draws_df, 2, quantile, probs = c(0.025, 0.975))))
quantiles_df <- tibble::rownames_to_column(quantiles_df, var = "variable")
names(quantiles_df)[2:3] <- c("q2.5", "q97.5")

S2.full.coef <- left_join(S2.full.coef, quantiles_df, by = "variable") 

# for table in appendix:
S2.full.coef.table <- S2.full.coef

# for reporting in text:
S2.full.coef <- S2.full.coef %>% 
  filter(grepl("^b_", variable)) %>% 
  mutate(variable = gsub("b_", "", variable)) %>% 
  mutate(variable = gsub("condition", "", variable)) %>% 
  data.frame(row.names = "variable")

# NULL MODEL
S2.null.coef <- summarise_draws(as_draws_df(S2.null.bm)) %>%
  filter(grepl("^b_", variable))

# 
# mean(S2.full.coef$ess_bulk)
# min(S2.full.coef$ess_bulk)
# max(S2.full.coef$ess_bulk)
# 
# mean(S2.null.coef$ess_bulk)
# min(S2.null.coef$ess_bulk)
# max(S2.null.coef$ess_bulk)


```

```{r rep_s3_inspect, echo = FALSE, include=F, eval=T, results='asis'}


S3.full.bm <- readRDS("../models/S3.full.bm.rds")
S3.null.bm <- readRDS("../models/S3.null.bm.rds")

S3.comp <- readRDS("../models/S3.comp.rds") 
S3.weights <- readRDS("../models/S3.weights.rds")


## POSTERIOR PREDICTICE CHECKS
## Check plots ...they look good, as expected in binomial models
# pp_check(S3.full.bm)
# pp_check(S3.null.bm)
# pp_check(S3.full.bm, type = "bars")
# pp_check(S3.null.bm, type = "bars")

# ### EFFECTICE SAMPLE SIZES
# ## inspect rhat --> always 1 --> good
# ## inspect Bull_ESS --> always > 1000 --> good
# summary(S3.full.bm)
# summary(S3.null.bm)

# # for reporting BULK_ESS
# S3.full.coef <- summarise_draws(as_draws_df(S3.full.bm)) %>%
#   filter(grepl("^b_", variable)) %>% 
#   mutate(variable = gsub("b_", "", variable)) %>% 
#   mutate(variable = gsub("condition", "", variable)) %>% 
#   data.frame(row.names = "variable")

# for reporting BULK_ESS and Coefficients
S3.full.coef <- summarise_draws(as_draws_df(S3.full.bm)) # ! standard is just 90% CrI

# NOTE: # as_draws_df() from posterior uses 90% CrIs
# we preregistered using 2.5% and 97.5% quantiles
draws_df <- as_draws_df(S3.full.bm)
quantiles_df <- as.data.frame(t(apply(draws_df, 2, quantile, probs = c(0.025, 0.975))))
quantiles_df <- tibble::rownames_to_column(quantiles_df, var = "variable")
names(quantiles_df)[2:3] <- c("q2.5", "q97.5")

S3.full.coef <- left_join(S3.full.coef, quantiles_df, by = "variable") 

# for table in appendix:
S3.full.coef.table <- S3.full.coef

# for reporting in text:
S3.full.coef <- S3.full.coef %>% 
  filter(grepl("^b_", variable)) %>% 
  mutate(variable = gsub("b_", "", variable)) %>% 
  mutate(variable = gsub("condition", "", variable)) %>% 
  data.frame(row.names = "variable")


# NULL MODEL
S3.null.coef <- summarise_draws(as_draws_df(S3.null.bm)) %>%
  filter(grepl("^b_", variable))

# mean(S3.full.coef$ess_bulk)
# min(S3.full.coef$ess_bulk)
# max(S3.full.coef$ess_bulk)
# 
# mean(S3.null.coef$ess_bulk)
# min(S3.null.coef$ess_bulk)
# max(S3.null.coef$ess_bulk)




```

<!-- Prepare Data for Plotting -->

```{r rep_S1_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T, warning = F, message=F}

# load model from rds
# S1.full.bm <- readRDS("../models/S1.full.bm.rds")
# table(rep.S1.bayes.data$condition)

nd1 <- tibble(z.age = rep(seq(from = min(rep.S1.bayes.data$z.age), to = max(rep.S1.bayes.data$z.age), length.out = 50),4),
             condition = c(rep("Representation",50), 
                           rep("Pars Pro Toto",50), 
                           rep("Complex Form Analogy",50), 
                           rep("Simple Form Analogy",50)), 
             # the four conditions in the data
             sex = rep(0,200),
             z.trial = rep(0,200))

# here we generate the fitted values based on the model
# the function fitted() takes in the model and the new dataset and generates a fitted values (inclucing upper and lower 95% CrI) for every row in the dataset
# because our dataset ranges from min age to max age in the data, we get the prediction for the age range in the data 
# but we could also generate predictions for different ages of course
f1 <- fitted(S1.full.bm, 
             newdata = nd1, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd1)%>%
  mutate(age = z.age + mean(rep.S1.bayes.data$ageinyears)) %>% # convert age back to the original scale by adding the mean of the data
  mutate(condition = factor(condition, levels = c(
        "Representation", # first level becomes reference
        "Pars Pro Toto", 
        "Simple Form Analogy", 
        "Complex Form Analogy")))

# summarize the data to include them in the plot later on
d1 <- rep.S1.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) %>% 
  mutate(condition = factor(condition, levels = c(
        "Representation", # first level becomes reference
        "Pars Pro Toto", 
        "Simple Form Analogy", 
        "Complex Form Analogy")))

p1 <- f1 %>%
  mutate(age = age * 365.25)%>%
   mutate(condition = factor(condition, levels = c(
        "Representation", # first level becomes reference
        "Pars Pro Toto", 
        "Simple Form Analogy", 
        "Complex Form Analogy"))) %>% 
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

nd1 <- add_colour(nd1)
f1  <- add_colour(f1)
d1  <- add_colour(d1)
p1  <- add_colour(p1)

```

```{r rep_S2_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T, warning = F, message=F}

# load model from rds
S2.full.bm <- readRDS("../models/S2.full.bm.rds")
# table(rep.S2.bayes.data$condition)

nd2 <- tibble(z.age = rep(seq(from = min(rep.S2.bayes.data$z.age), to = max(rep.S2.bayes.data$z.age), length.out = 50),4),
              condition = c(rep("Relative Position",50), 
                            rep("Absolute Position",50), 
                            rep("Orientation of Feature",50), 
                            rep("Orientation of Object",50)),
              sex = rep(0,200),
              z.trial = rep(0,200))

# here we generate the fitted values based on the model
# the function fitted() takes in the model and the new dataset and generates a fitted values (inclucing upper and lower 95% CrI) for every row in the dataset
# because our dataset ranges from min age to max age in the data, we get the prediction for the age range in the data 
# but we could also generate predictions for different ages of course
f2 <- fitted(S2.full.bm, 
             newdata = nd2, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd2)%>%
  mutate(age = z.age + mean(rep.S2.bayes.data$ageinyears)) %>% # convert age back to the original scale by adding the mean of the data
  mutate(condition = factor(condition, levels = c(
    "Absolute Position", # first level becomes reference
    "Relative Position", 
    "Orientation of Object", 
    "Orientation of Feature")))

# summarize the data to include them in the plot later on
d2 <- rep.S2.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) %>% 
  mutate(condition = factor(condition, levels = c(
    "Absolute Position", # first level becomes reference
    "Relative Position", 
    "Orientation of Object", 
    "Orientation of Feature")))

p2 <- f2 %>%
  mutate(age = age * 365.25)%>%
  mutate(condition = factor(condition, levels = c(
    "Absolute Position", # first level becomes reference
    "Relative Position", 
    "Orientation of Object", 
    "Orientation of Feature"))) %>% 
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )

nd2 <- add_colour(nd2)
f2  <- add_colour(f2)
d2  <- add_colour(d2)
p2  <- add_colour(p2)

```

```{r rep_S3_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T, warning = F, message=F}


# load model from rds
S3.full.bm <- readRDS("../models/S3.full.bm.rds")
# table(rep.S3.bayes.data$condition)

nd3 <- tibble(z.age = rep(seq(from = min(rep.S3.bayes.data$z.age), to = max(rep.S3.bayes.data$z.age), length.out = 50),4),
              condition = c(rep("Number of Object",50), 
                            rep("Number of Feature",50), 
                            rep("Size of Object",50), 
                            rep("Size of Feature",50)),
              sex = rep(0,200),
              z.trial = rep(0,200))

# here we generate the fitted values based on the model
# the function fitted() takes in the model and the new dataset and generates a fitted values (inclucing upper and lower 95% CrI) for every row in the dataset
# because our dataset ranges from min age to max age in the data, we get the prediction for the age range in the data 
# but we could also generate predictions for different ages of course
f3 <- fitted(S3.full.bm, 
             newdata = nd3, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd3)%>%
  mutate(age = z.age + mean(rep.S3.bayes.data$ageinyears)) %>% # convert age back to the original scale by adding the mean of the data
  mutate(condition = factor(condition, levels = c(
    "Size of Object", # first level becomes reference
    "Size of Feature", 
    "Number of Object", 
    "Number of Feature")))

# summarize the data to include them in the plot later on
d3 <- rep.S3.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) %>% 
  mutate(condition = factor(condition, levels = c(
    "Size of Object", # first level becomes reference
    "Size of Feature", 
    "Number of Object", 
    "Number of Feature")))

p3 <- f3 %>%
  mutate(age = age * 365.25)%>%
  mutate(condition = factor(condition, levels = c(
    "Size of Object", # first level becomes reference
    "Size of Feature", 
    "Number of Object", 
    "Number of Feature"))) %>% 
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )

nd3 <- add_colour(nd3)
f3  <- add_colour(f3)
d3  <- add_colour(d3)
p3  <- add_colour(p3)

```

<!-- Plotting aktuellste Version-->

```{r rep_S1_bayes_fullmodel_plotting_new, echo=FALSE, eval=F, warning = F, message=F}

# place images on the plot
# while (!is.null(dev.list())) dev.off()


# Create main plot
main_plot <- ggplot() +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey70", alpha = 0.75) +
  
  geom_point(data = d1, aes(x = ageinyears, y = mean, colour = colour), alpha = 0.5, shape = 1, size = 2) +
  
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = colour, colour = colour),
              stat = "identity", alpha = 0.2, linewidth = 0.8) +
  
  geom_point(data = p1, aes(x = days/365.25, y = 0.5, fill = colour, colour = colour), size = 4, shape = 21, stroke = 1) +
  geom_point(data = p1, aes(x = days/365.25, y = 0.5, fill = "black", colour = "black"), size = 0.5, shape = 21, stroke = 1) +
  geom_text(data = p1, aes(label = months, x = days/365.25, y = 0.13, colour = "black", fontface = "bold"),
            angle = 90, size = 3.2, vjust = 0.5) +
  
  geom_text(data = p1, aes(label = "months", x = days/365.25, y = .31, colour = "black", fontface = "bold"), 
            angle = 90, size = 3.2, vjust = 0.5) +
  
  scale_colour_identity() +
  scale_fill_identity() +
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) + # Multiply by 100 & add %  
  
  
  facet_grid(cols = vars(condition)) +
  
  labs(x = "Age", y = "Proportion Correct") +
  
  coord_cartesian(ylim = c(0, 1), xlim = c(2.7, 7.3)) +   # Allow more Y space for image
  
  theme_minimal(base_size = 13) +
  theme(
    panel.border = element_rect(colour = "grey30", fill = NA, size = 1),
    strip.background = element_rect(colour = "grey30", size = 1),
    strip.text = element_text(face = "bold", size = rel(0.8), 
                              margin = margin(t = 5, b = 45)), # HIER STRIPE SPACING via b =
   # strip.switch.pad.grid = unit(0, "cm"),
    axis.title = element_text(face = "bold", size = rel(0.8)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = "none",
    panel.grid.minor = element_blank()
  )

# adding images -----
# load images
image_1 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[1], ".png"))
image_2 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[2], ".png"))
image_3 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[3], ".png"))
image_4 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[4], ".png"))
# create grobs
image_1_grob <- rasterGrob(image_1, interpolate = TRUE)
image_2_grob <- rasterGrob(image_2, interpolate = TRUE)
image_3_grob <- rasterGrob(image_3, interpolate = TRUE)
image_4_grob <- rasterGrob(image_4, interpolate = TRUE)



final_plot <- ggdraw(main_plot) +
  draw_grob(image_1_grob, x = 0.071, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_2_grob, x = 0.3, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_3_grob, x = 0.527, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_4_grob, x = 0.755, y = 0.752, width = 0.25, height = 0.15)

# Save  ------------
ggsave(
  filename = "../illustrations/plot_study1.png",
  plot = final_plot,
  device = "png",
  width = 8, height = 3.5,
  dpi = 300,
  units = "in",
  bg = "white"
)

# # display plot
# img <- image_read("../illustrations/plot_study1.png")
# 
# windows(width = 15, height = 10)  # On Windows
# plot(img)


```

```{r rep_S2_bayes_fullmodel_plotting_new, echo=FALSE, eval=F, warning = F, message=F}

# Create main plot
main_plot <- ggplot() +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey70", alpha = 0.75) +
  
  geom_point(data = d2, aes(x = ageinyears, y = mean, colour = colour), alpha = 0.5, shape = 1, size = 2) +
  
  geom_smooth(data = f2, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = colour, colour = colour),
              stat = "identity", alpha = 0.2, linewidth = 0.8) +
  
  geom_point(data = p2, aes(x = days/365.25, y = 0.5, fill = colour, colour = colour), size = 4, shape = 21, stroke = 1) +
  geom_point(data = p2, aes(x = days/365.25, y = 0.5, fill = "black", colour = "black"), size = 0.5, shape = 21, stroke = 1) +
  geom_text(data = p2, aes(label = months, x = days/365.25, y = 0.13, colour = "black", fontface = "bold"),
            angle = 90, size = 3.2, vjust = 0.5) +
  
  geom_text(data = p2, aes(label = "months", x = days/365.25, y = .31, colour = "black", fontface = "bold"), 
            angle = 90, size = 3.2, vjust = 0.5) +
  
  scale_colour_identity() +
  scale_fill_identity() +
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) + # Multiply by 100 & add %  
  
  
  facet_grid(cols = vars(condition)) +
  
  labs(x = "Age", y = "Proportion Correct") +
  
  coord_cartesian(ylim = c(0, 1), xlim = c(2.7, 7.3)) +   # Allow more Y space for image
  
  theme_minimal(base_size = 13) +
  theme(
    panel.border = element_rect(colour = "grey30", fill = NA, size = 1),
    strip.background = element_rect(colour = "grey30", size = 1),
    strip.text = element_text(face = "bold", size = rel(0.8), 
                              margin = margin(t = 5, b = 45)), # HIER STRIPE SPACING via b =
   # strip.switch.pad.grid = unit(0, "cm"),
    axis.title = element_text(face = "bold", size = rel(0.8)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = "none",
    panel.grid.minor = element_blank()
  )

# adding images -----
# load images
image_1 <- image_read(paste0("../illustrations/plotexample ", levels(d2$condition)[1], ".png"))
image_2 <- image_read(paste0("../illustrations/plotexample ", levels(d2$condition)[2], ".png"))
image_3 <- image_read(paste0("../illustrations/plotexample ", levels(d2$condition)[3], ".png"))
image_4 <- image_read(paste0("../illustrations/plotexample ", levels(d2$condition)[4], ".png"))
# create grobs
image_1_grob <- rasterGrob(image_1, interpolate = TRUE)
image_2_grob <- rasterGrob(image_2, interpolate = TRUE)
image_3_grob <- rasterGrob(image_3, interpolate = TRUE)
image_4_grob <- rasterGrob(image_4, interpolate = TRUE)



final_plot <- ggdraw(main_plot) +
  draw_grob(image_1_grob, x = 0.071, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_2_grob, x = 0.3, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_3_grob, x = 0.527, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_4_grob, x = 0.755, y = 0.752, width = 0.25, height = 0.15)

# Save  ------------
ggsave(
  filename = "../illustrations/plot_study2.png",
  plot = final_plot,
  device = "png",
  width = 8, height = 3.5,
  dpi = 300,
  units = "in",
  bg = "white"
)

# # display plot
# img <- image_read("../illustrations/plot_study2.png")
# 
# windows(width = 15, height = 10)  # On Windows
# plot(img)




```

```{r rep_S3_bayes_fullmodel_plotting_new, echo=FALSE, eval=F, warning = F, message=F}


# Create main plot
main_plot <- ggplot() +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey70", alpha = 0.75) +
  
  geom_point(data = d3, aes(x = ageinyears, y = mean, colour = colour), alpha = 0.5, shape = 1, size = 2) +
  
  geom_smooth(data = f3, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = colour, colour = colour),
              stat = "identity", alpha = 0.2, linewidth = 0.8) +
  
  geom_point(data = p3, aes(x = days/365.25, y = 0.5, fill = colour, colour = colour), size = 4, shape = 21, stroke = 1) +
  geom_point(data = p3, aes(x = days/365.25, y = 0.5, fill = "black", colour = "black"), size = 0.5, shape = 21, stroke = 1) +
  geom_text(data = p3, aes(label = months, x = days/365.25, y = 0.13, colour = "black", fontface = "bold"),
            angle = 90, size = 3.2, vjust = 0.5) +
  
  geom_text(data = p3, aes(label = "months", x = days/365.25, y = .31, colour = "black", fontface = "bold"), 
            angle = 90, size = 3.2, vjust = 0.5) +
  
  scale_colour_identity() +
  scale_fill_identity() +
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) + # Multiply by 100 & add %  
  
  
  facet_grid(cols = vars(condition)) +
  
  labs(x = "Age", y = "Proportion Correct") +
  
  coord_cartesian(ylim = c(0, 1), xlim = c(2.7, 7.3)) +   # Allow more Y space for image
  
  theme_minimal(base_size = 13) +
  theme(
    panel.border = element_rect(colour = "grey30", fill = NA, size = 1),
    strip.background = element_rect(colour = "grey30", size = 1),
    strip.text = element_text(face = "bold", size = rel(0.8), 
                              margin = margin(t = 5, b = 45)), # HIER STRIPE SPACING via b =
    # strip.switch.pad.grid = unit(0, "cm"),
    axis.title = element_text(face = "bold", size = rel(0.8)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = "none",
    panel.grid.minor = element_blank()
  )

# adding images -----
# load images
image_1 <- image_read(paste0("../illustrations/plotexample ", levels(d3$condition)[1], ".png"))
image_2 <- image_read(paste0("../illustrations/plotexample ", levels(d3$condition)[2], ".png"))
image_3 <- image_read(paste0("../illustrations/plotexample ", levels(d3$condition)[3], ".png"))
image_4 <- image_read(paste0("../illustrations/plotexample ", levels(d3$condition)[4], ".png"))
# create grobs
image_1_grob <- rasterGrob(image_1, interpolate = TRUE)
image_2_grob <- rasterGrob(image_2, interpolate = TRUE)
image_3_grob <- rasterGrob(image_3, interpolate = TRUE)
image_4_grob <- rasterGrob(image_4, interpolate = TRUE)



final_plot <- ggdraw(main_plot) +
  draw_grob(image_1_grob, x = 0.071, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_2_grob, x = 0.3, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_3_grob, x = 0.527, y = 0.752, width = 0.25, height = 0.15) +
  draw_grob(image_4_grob, x = 0.755, y = 0.752, width = 0.25, height = 0.15)

# Save  ------------
ggsave(
  filename = "../illustrations/plot_study3.png",
  plot = final_plot,
  device = "png",
  width = 8, height = 3.5,
  dpi = 300,
  units = "in",
  bg = "white"
)

# # display plot
# img <- image_read("../illustrations/plot_study3.png")
# 
# windows(width = 15, height = 10)  # On Windows
# plot(img)
# 


```

<!-- weitere zahlen -->

```{r summaryresults,  echo=FALSE, warning=F, message=F, eval=T}

p_all <- rbind(p1,p2,p3) %>% arrange(months)
p_all <- data.frame(p_all, row.names = "condition")

```

```{r additionalanalyses, echo=FALSE, warning=F, message=F, eval=F}

# 
# possible add-ons
# a model including all Conditions
# comparing difficulty across items and tasks
# evaluating manipulations such as complex/simple; 
# reaction time analyses
# 
# Additional Analyses:
# 
# object vs feature
# - orfe vs orob
# - sife vs siob
# - nufe vs nuob
# 
# round vs angular
# - Study One Study1 - cue A = rund, cue B eckig ...if one of them is easier
# 
# Reaction Times
# - just reaction times and perc correct across aged

```

<!-- Hier gehts los -->

# Introduction

not ready yet...

[See googledocs for intro and
discussion.](https://docs.google.com/document/d/1nLlkREwo1JXngqy9Dfyhx5kdV4ue9w0fRJ61O8gDNIc/edit?usp=sharing)

# General Methods

All three studies presented below share methodological and analytic approaches.
For the convenience of the reader, common features of the procedure,
participant recruiting and stimulus design are reported first before
discussing the three studies respectively. All studies were
preregistered online prior to data collection (cf. [Study
1](https://aspredicted.org/SJT_H7F), [Study
2](https://aspredicted.org/L2H_XC7), and [Study
3](https://aspredicted.org/DR4_B4B)). [MB: im paper müsste der Link ausgeschreiben sein, nicht hinterlegt]

[MB: links zu repo mit data und analysis scripts sowie code für die studien?]

## Data Collection and Setup

In order to continuously trace the development of symbolic competences
across the preschool years, for each study we aimed to test two children
per month of age between the third and the seventh birthday for a total
of 96 participants while balancing male and female
participants. As children participated on the basis of availability and
data were collected by several experimenter teams visiting different
institutions in parallel, the resulting final samples slightly exceed
this preregistered minimum sample size. The final sample approximates an
equal distribution of male and female participants and aligns with
conventions in the field in providing a minimum of 24 participants per
study and year of age (cf. Appendix A figure
\@ref(fig:suppl-participants-dots)). All participants were recruited in
*MASKED FOR REVIEW*, a medium-sized middle-European city, and came from
a predominantly white population of middle to high income families. They
were contacted via a database of participants for child development
studies to which their parents had voluntarily signed up. Children were
tested in day- and after schoolcare for the most part, and occasionally
in the lab or at home. The studies were reviewed and approved by an
internal ethics committee at the *MASKED FOR REVIEW*. Data collection
took place from June 2022 to February 2023.

## Setup and Procedure

During test sessions, a child and an experimenter sat down together to
play a picture-book-style hiding game presented on a touch-screen
laptop. Verbal instructions were played back by the experimental script.
Experimenters supervised children during data collection and
occasionally reacted with a fixed set of verbal prompts when children
were not following the presentation ("Oh look, the game continues!").
Test sessions always took place in a quiet separate room. See figure
\@ref(fig:plot-figure-setup) for an illustration of the setup.

```{r plot-figure-setup, fig.cap = "*Setup.* Experimenters were sitting behind the children in order to not distract them while supervising data collection.", fig.align = "center", echo = FALSE, out.width = "70%"}

knitr::include_graphics(knitr::plot_crop("../illustrations/setup room.png"))

```

*Familiarisation.* Experimenters invited the participants to join a
hiding game and initially instructed them to follow the narration of the
story. First, the presentation introduced a cartoon monkey. This
character then placed two cups on the bottom left and right side of the
screen. After holding up a banana, one of the barriers was lifted, the
banana was placed underneath one of the cups and the barrier was
lowered. Children were now prompted to touch the hiding place and in
doing so the barrier of their choice was lifted to reveal the banana
again if they chose correctly. The experimental script played back
prerecorded feedback upon children's choice ("yes, great job!"; "No,
that's not it. Let's try again!") during the familiarization (cf.
Appendix B, figure \@ref(fig:suppl-plot-setupfamtest) A) [MB: die Figure würde ich sagr nit ins paper nehmen - vll neben plot-figure setup, also beides zu einer Figure mergen]. In order to
succeed during familiarization, children solely had to remember where
the item went and touch this part of the screen a few seconds later. To
ensure that children were familiar with the goal of the game and the
touch interface, they first had to complete a set of four to eight
familiarization trials with a success rate of 75%. In case a child did
not reply correctly in three out of four trials, another four
familiarization trials were provided. If the child was correct in six
out of eight trials, she was included in the main sample. Children that
did not succeed during familiarization were allowed to participate but
their data was not submitted to analysis. These children are reported
below as failing the familiarization phase.

*Test.* The main phase of the study commenced with announcing that the
cartoon character had an idea for a new game. The narration conveyed
that children were not allowed to see where the banana would be hidden,
but that the monkey would help them find it. Hence, the cartoon
character was established as a knowledgeable and benevolent partner in a
cooperative coordination game. The hiding sequence was identical to the
familiarization phase, however the placement of the banana was concealed
by a barrier covering the lower half of the screen. After the hiding
phase, the monkey then held up a piece of paper and a pencil. Pencil
movement and a short scribble sound indicated that the monkey was
drawing. Children were reminded that the monkey was going to help them.
Finally, participants were prompted with the phrase "Where is the
banana?" and the monkey's drawing was placed in the center between the
two barriers. The drawing served as a cue to guide children's choice. In
the most basic experimental condition in study one (*Representation*),
each hiding place, for example, showed either a solid blue circle or
square and the paper displayed a simple outline drawing of one the
shapes. Upon making a choice by touching the hiding places, children
received no feedback and there was no reveal animation. Rather,
children's choice was acknowledged with neutral feedback ("Ah, thank
you") leading over to the next trial (cf. Appendix B, figure
\@ref(fig:suppl-plot-setupfamtest) B).

Except for the geometric shapes displayed on the hiding places and the
respective drawing, the experimental presentation was identical for all
test trials. A single trial lasted roughly 20 to 60 seconds, depending
on how swiftly children chose. Each study presented four different
experimental conditions with four trials each in a blocked order for a
maximum of 16 test trials. Test sessions lasted about 12 minutes in
total. The order of conditions was counterbalanced across participants.
Children occasionally wished to stop before completing all trials,
resulting in minor deviations of the total number of trials per
condition that were submitted to analysis. For an overview of the
average number of trials participants received in each condition, see
tables \@ref(tab:suppl-descriptives-S1),
\@ref(tab:suppl-descriptives-S2) and \@ref(tab:suppl-descriptives-S3) in
Appendix C. In line with the preregistration, children had to complete a
minimum of eight test trials to be included in analysis. Respective
exclusions are reported separately for each study.

## Stimuli and Counterbalancing

The set of studies presented here regard communication as a means for
solving coordination problems. In the most simple small-world scenario
an utterance or symbol, such as a graphic display, provided by a helpful
interlocutor should enable an addressee to shift attention to, or help
decide for one out of two options that are relevant in a particular
practical context and even in the absence of conventions
[@wittgenstein2009philosophical]. For the purpose of operationalization,
the context in the studies presented below is provided by a game of hide
and seek and the options are two hiding places that are distinct by
means of the graphic displays they are marked with. The aim was to test
at what age children become able to spontaneously use graphic displays
employing various dimensions of symbol-referent relationships. For this,
the graphic displays presented as referents were designed to saliently
differ in one relevant dimension and to be as similar as possible with
regard to other surface features. The referent, on the other hand, was a
reduced and less straight-lined graphic display akin to a hand drawing
that had something in common with one of the referents and is thereby
referring to it while it remains distinct with regard to other surface
features. In test trials, one of the possible referents serves as a
target and the other as a distractor. For counterbalancing, a second
referent was designed to refer to the other target, such that across
participants the same referents serve equally often as targets and
distractors. For an illustration of trial composition, see figure
\@ref(fig:suppl-plot-setup-compose) in appendix B. For each of the
conditions in the three studies below, four sets of stimuli were
designed, consisting of two blue shapes serving as target or distractor,
and two drawings that could serve as cues. Each condition covers a
particular type of symbol-referent relationship via four stimulus
versions with two variations each. For an example, consider figure
\@ref(fig:suppl-plot-S1-stimuli) [MB: auch hier, die Figure würde ich vll soagr mit ins apper nehmen, also dass man die ganzen stimuli im paper hat] in appendix B. Panel (A) shows all
stimuli for the *Representation* condition. The first column exemplifies
a set of targets (a blue square and circle) and referents (outline
drawings of a square and circle). During test, participants are
presented with four test trials per condition, each composed of the
shapes of a single column. During testing, a child sees each trial
combination only once and with only one of the two possible cues. Across
children, the position (left/right) of the referent, and the identity of
the cue are counterbalanced.

## Data Handling and Analyses

In each test trial, participants were prompted to touch one of the two
choice options. Choices were logged by the experimental script and
directly coded as correct or incorrect. Exclusions of data were solely
made on the level of participants with regard to the exclusion criteria
reported above. The analyses modeled participants' binary choices to
predict the probability of children interpreting cues correctly and to
model how this probability would change as a function of their age.
Logistic Bayesian generalized linear mixed models (GLMM) fitted
children's responses (0/1) as a function of their age, the experimental
condition and an interaction between trial and condition. Trial and sex
were included as fixed effects to be controlled for. Trial number was
added as a random slope within subject [MB: random effects? ]. To evaluate the relevance of age
and condition for children’s performance, a full model was compared with
a reduced model lacking the interaction of age and condition using
Widely Applicable Information Criterion (WAIC) scores and weights
[@mcelreath2018statistical] as well as the difference in Expected Log
Predictive Density (ELPD) via the function *loo_compare*. Furthermore,
model estimates were inspected for the different predictors including
their 95% Credible Interval (CrI). In each study, the condition
hypothesized as the most simple was set as the reference level within
conditions to make interpretation of model estimates convenient. All
Bayesian models used default priors and were run in Stan [MB: citation statt link]
(<http://mc-stan.org/>) via the function *brm* of the package *brms*
[@burkner2017brms]. To answer the main research question of when
children as a group systematically make correct choices in any of the
conditions outlined below, we use fitted models to predict the
developmental trajectory (with 95% CrI) of group level performance drawn
from values of the posterior predicted distribution via the function
*fitted*. These trajectories and CrIs were plotted by age. The criterion
for settling when children performed above chance was the point at which
the lower bound of the 95% CrI for a particular trajectory did no longer
overlap with a mid-line demarcating the 50% chance level. All analyses
were preregistered prior to data collection. Analyses deviate from the
preregistered analyses when comparing models via ELPD differences
[@sivula2020uncertainty]. This was simply not as common by the time of
preregistration. For the convenience of the reader, we also provide
conventional analyses binning participants according to their age in
years. To test whether group-level performance was above chance in all
experimental groups, two-tailed one-sample t-tests with a chance level
set to .5 were computed and are accompanied by Cohen's *d* as a
standardized effect size for significance testing (cf. Appendix C Tables
\@ref(tab:suppl-descriptives-S1), \@ref(tab:suppl-descriptives-S2) and
\@ref(tab:suppl-descriptives-S3)).

# Study 1

Study 1 aimed to establish a baseline for children's performance and for
evaluating task demands by providing the most simple symbol-referent
relationship possible, where the cue is a direct representation of the
target (*Representation*). From this, three further conditions were
derived that were also employing form or shape as a means for
establishing reference but that were less iconic by either reducing the amount of information provided (*Pars Pro Toto*), or the
amount of similarity between symbol and referent (*Simple Form Analogy*,
*Complex Form Analogy).* We hypothesized (and preregistered) that as a group children will
first succeed with *Representation*, then *Pars Pro Toto*, *Simple Form
Analogy* and finally *Complex Form Analogy*.

## Stimuli

To make the four conditions in study 1 as comparable as possible, they
are all employing the same target stimuli (cf. figure
\@ref(fig:suppl-plot-S1-stimuli), top rows in panels A-B; appendix B).
In addition the two referents within a trial can be seen as the round
and square equivalents of each other which makes their overall
appearance even more similar and aids matching the surface they cover.
For the condition *Representation,* the graphical cue is a direct
representation, that is an outline drawing, of the referent. The second
condition, *Pars Pro Toto,* refers to the targets by means of a
part-whole relationship. This is still in principle representational but
provides less information and may require children to complete the
shapes according to gestalt principles. While this completion is easiest
in the first column in panels A to B (ibid.) due to the canonical shapes
(square, circle) it is less obvious in columns 2 to 4 (ibid.) with the
less iconic [MB: meinst du hier canonical? iconic klingt komisch weil man denkt manche wäre noch "ikonischer"] shapes albeit they are vertically and horizontally
symmetrical on purpose. For comparability, *Pars Pro Toto* uses the same
graphical cues as *Representation* but cut in half at a horizontal
mid-line. A Stimulus set of an individual trial either uses the top or
bottom half, but both variations are counterbalanced across trials.
Stimulus variations with a division at the vertical axis were avoided as
such cues are likely to have been read as arrows by children of the age
that were tested here [@kachelarrowsInPrep]. Two further conditions
aimed to abstract from the original representational symbol-referent
relationship by providing graphical analogies in form. In both *Simple
Form Analogy* and *Complex Form Analogy* the cue was an abstract line
drawing being more round or rectangular, thereby referring to either the
round or rectangular equivalent of the target shapes. As this has not
been done before in developmental research, our aim was to provide two
versions of form analogies both supporting children's comprehension in
distinct ways. In *Simple Form Analogy*, the cues are less dense and
therefore more simple to grasp, whereas the more complex versions in
*Complex Form Analogy* provide more information. Arguably either
variation may support feature extraction. As before, the cues in both
conditions are direct equivalents with either round or edgy drawing line
progressions. For an overview of all stimuli in Study 1, see figure
\@ref(fig:suppl-plot-S1-stimuli) in appendix B.

## Participants

A sample of `r rep.age.table.data["study1", "N"]` children (M =
`r rep.age.table.data["study1", "Mean"]` months, SD =
`r rep.age.table.data["study1", "SD"]` months, range
`r rep.age.table.data["study1", "Min"]` -
`r rep.age.table.data["study1", "Max"]` months;
`r rep.age.table.data["study1", "female"]` female) participated in
Study 1. In addition, `r rep.drop.table.data["study1", "N"]` children
(`r rep.drop.table.data["study1", "female"]` female) were tested but
excluded from analysis for not succeeding during familiarization (N =
`r rep.drop.table.data["study1", "fail_in_fam"]`), for not completing at
least eight out of 16 test trials (N =
`r rep.drop.table.data["study1", "quit_early"]`), or due to being fussy
(N = `r rep.drop.table.data["study1", "fussy_child"]`). For
`r rep.drop.table.data["study1", "language"]` children, experimenters
only learned during testing that they were not fluent enough in German
to participate as their families had only recently migrated. Finally,
`r rep.drop.table.data["study1", "technical"]` children had to be
excluded due to technical issues. For a graphical overview of
participants and exclusions across all three studies, see Appendix A
figures \@ref(fig:suppl-participants-dots) and
\@ref(fig:suppl-exclusions-dots).

## Analysis

A total of `r sum(rep.s1.trials$Trials)` trials (mean per condition =
`r mean(rep.s1.trials$Trials)`, range: `r min(rep.s1.trials$Trials)` -
`r max(rep.s1.trials$Trials)`) from
`r rep.age.table.data["study1", "N"]` participants were submitted for
analysis. The full model notation was
`correct ~ condition*z.age + z.trial + sex + (z.trial | subid)`. In
addition, a null model lacking the interaction of condition and age was
fitted.

## Results

Posterior predictive checks (PPC) for both full and null model indicated
excellent fit of observed data and model predictions (see supplement D
for more information). Comparing the models using weights based on the
Widely Applicable Information Criterion (WAIC) yielded
`r round(S1.weights["S1.full.bm","value"]*100,2)`% of the model weight
for the full model, and
`r round(S1.weights["S1.null.bm","value"]*100,2)`% for the null model.
Hence, the full model generally had a higher probability of making
accurate predictions. Directly comparing the models' WAIC via expected
log predictive density (ELPD) corroborates this (ELPD WAIC; full model =
`r round(S1.comp["S1.full.bm", "elpd_waic"],2)`; null model =
`r round(S1.comp["S1.null.bm", "elpd_waic"],2)`). The standard error of
the difference in predictive accuracy (SE =
`r round(S1.comp["S1.null.bm", "se_diff"],2)`), however is numerically larger than
the difference itself (ELPD diff =
`r round(S1.comp["S1.null.bm", "elpd_diff"],2)`) [MB: hier hattest du "lower" geschrieben. die rule of thumb wäre aber dass der diff 2*mal größer sein sollte als der SE]. While the full model
slightly exceeds in predictive power, evidence in favor of this model is
not decisive. A similar comparison via Leave-One-Out Cross-Validation
(LOO) provided essentially the same results. In absence of conclusive
evidence for either model, we report the results for the full model in
line with the preregistration.

Relative to the *Representation* condition, the *Simple Form Analogy*
($\beta$ = `r S1.full.coef["SimpleFormAnalogy", "mean"]`, 95% CrI
[`r S1.full.coef["SimpleFormAnalogy", "q2.5"]`,
`r S1.full.coef["SimpleFormAnalogy", "q97.5"]`) and *Complex Form
Analogy* ($\beta$ = `r S1.full.coef["ComplexFormAnalogy", "mean"]`, 95% CrI
[`r S1.full.coef["ComplexFormAnalogy", "q2.5"]`,
`r S1.full.coef["ComplexFormAnalogy", "q97.5"]`) have a considerably
lower probability of correct responses. The *Pars Pro Toto* condition
has no clear difference from the reference condition ($\beta$ =
`r S1.full.coef["ParsProToto", "mean"]`, 95% CrI
[`r S1.full.coef["ParsProToto", "q2.5"]`,
`r S1.full.coef["ParsProToto", "q97.5"]`). Interaction terms between age
and condition were not reliably different from zero. The developmental
curves for each condition have essentially similar trajectories.
Interaction effects with age were not relevant with the exception of
*Pars Pro Toto* [MB: das ist verwirrend, erst sagst du sie sind nicht reelvant und dann sagst du doch für eine Bedingung]. Here, the interaction with age was positive and just
above zero ($\beta$ = `r S1.full.coef["ParsProToto:z.age", "mean"]`, 95%
CrI [`r S1.full.coef["ParsProToto:z.age", "q2.5"]`,
`r S1.full.coef["ParsProToto:z.age", "q97.5"]`), suggesting that
performance increased more steeply across the age range than in the
reference condition *Representation*. Generally, participants’
performance improved with age in all conditions ($\beta$ =
`r S1.full.coef["z.age", "mean"]`, 95% CrI
[`r S1.full.coef["z.age", "q2.5"]`, `r S1.full.coef["z.age", "q97.5"]`).
In contrast, trial number has no clear effect on performance ($\beta$ =
`r S1.full.coef["z.trial", "mean"]`, 95% CrI
[`r S1.full.coef["z.trial", "q2.5"]`,
`r S1.full.coef["z.trial", "q97.5"]`), suggesting no evidence for
learning or fatigue throughout the test session.

Finally, by tracing when the lower bound of the 95% CrI exceeds the
chance level of 50%, it is possible to report when children's group
level performance becomes robustly systematic in favor of the correct
choice. In study 1, children perform above chance in the
*Representation* condition at least as early as
`r p1$months[p1$condition == "Representation"]` months, which is the
lower limit of the age-range. Quickly after, at
`r p1$months[p1$condition == "Pars Pro Toto"]` months, children succeed
in the *Pars Pro Toto* condition. In the more abstract conditions
*Simple Form Analogy* and *Complex Form Analogy*, preschoolers meet
criterion at `r p1$months[p1$condition == "Simple Form Analogy"]` and
`r p1$months[p1$condition == "Complex Form Analogy"]` months
respectively. For a side-by-side comparison of the developmental
trajectories in the four conditions of study 1, see figure
\@ref(fig:plot-study1). See appendix C table
\@ref(tab:suppl-S1-coef-table) for a full overview of coefficients for
the full model, and table \@ref(tab:suppl-descriptives-S1) for
additional conventional analyses binning participants according to their
age in years.

```{r plot-study1, fig.cap = "*Developmental Trajectories for all Conditions in Study 1.* Panels illustrate an example stimulus combination (distractor, cue, target) and results for the conditions. Coloured lines indicate smoothed mean performance by age. Shaded areas represent 95% CIs. The dashed line demarcates chance level and the dots represent individual means. The coloroured dots and annotation indicate when children's performance exceeds chance level.", fig.align = "center", echo = FALSE, out.width = "100%"}


knitr::include_graphics(knitr::plot_crop("../illustrations/plot_study1.png"))

```

## Discussion

A main finding is that children succeed in *Representation* already and
robustly at 36 months of age, which is the lower end of our age-range.
Based on the literature, it is reasonable to assume that also in our
setup, children would be able to solve the task at hand between the
second and third birthday [@deloache1992picture; @callaghan2000factors;
@callaghan1999early]. In the context of the series of studies presented
below, this result establishes that the task design and setup are
sufficiently clear even for the youngest children in the sample. This is
also partially ensured by the 75% criterion of correct choices employed
in the familiarization phase. At the same time, the drop out rates due
to problems with this familiarization criterion were comparably high at
the lower end of the age-range (cf. Appendix A,
\@ref(fig:suppl-exclusions-dots)). Testing children younger than three
years of age would likely have required additional instructions or
slower pacing of the presentation which counters comparability. As it
stands, the setup presented here worked perfectly despite providing the
exact same task across the considerably large age-range of four years
from the end of toddlerhood up into school age. The results for
*Representation* further illustrate that already by three years of age
children understand a representational symbol-referent relationship as
operationalized here - with full-color target shapes and loose outline
drawings as cues - in the concrete context of the
picture-book-style object-choice-task at hand. That is, task demands and
framing do not seem to tax children's performance from three years
onwards. Relatedly, it is quite interesting to observe that even within
the most simple symbol-referent relationship, a small number of
participants between four and six years of age struggled with the task
or maybe simply did not care much for making correct choices (cf. dots
representing individual performance in \@ref(fig:plot-study1)). This
maybe seen as a baseline of failure that puts the numbers of children
into perspective that are not succeeding in the more difficult
conditions discussed below [MB: würde ich rausnehmen ab "Relatedly, it is quite interesting ..." - dafür machen wir ja die Analyse, das manche Kinder keinen Bock haben ist da ja eingepreist]. Finally, we can observe that the CrI around
the estimated mean in the graphic presentation is getting narrower,
showing that - as children get older - they are behaving more uniformly.
*Representation*, hence, provides also a baseline for the uncertainty to
that can be expected with the operationalization we used. For all of
these reasons, *Representation* provides a robust and clear conceptual
canvass against which the developmental patterns of all other
symbol-referent relationships can be discussed [MB: sehr gut, könnte man aber gut streamlinene und vll kürzen].

The first case in question then is *Pars Pro Toto*. Despite using
identical targets and - even partially identical cues - as in
*Representation* children succeed only at 40 months. The symbol-referent
relationship in *Pars pro Toto* is still based in visual similarity but
requires a slight inference, namely that a part can stand for a whole.
The interaction with age shows that performance improves more quickly
with age and that the area covered by the upper and lower CrI bounds
shrinks considerably across the age range. *Pars Pro Toto*, hence,
stands out as a clear example for a task that children come to master
early and within the age-range tested here, that generally is not
demanding for preschoolers in general. This contrasts with the less
steep developmental trajectories observed in the other two conditions of
study 1. *Simple Form Analogy* and *Complex form Analogy* share highly
similar developmental trajectories and, when considering the entire
age-range, appear equally difficult for participants. They appear as
examples for symbol-referent relationships that are demanding for the
oldest children in the sample, and may arguably require a second to
solve or to describe verbally - even for adults. Establishing reference
via an analogy in form is quite unconventional in graphic communication [MB: Den satz würde ich rausnehmen, da könnte man nachfragen: wenn das so ungewöhnlich ist, warum habt ihr es dan gemacht?].
Both conditions, here, stand out as conditions that are based first and
foremost in visual similarity but are conceptually demanding at the same
time. With regard to the influence of surface features, group level
success occurs slightly earlier with the reduced cues employed in
*Simple Form Analogy*. This suggests a slight benefit of a stimuli that
are easier to grasp in line the literature on analogical reasoning
[@gentner1988metaphor; @richland2006children]. Finally, overall results
are perfectly in line with the hypothesized developmental succession of
group level success coming to pass first with *Representation*, then
*Pars Pro Toto*, *Simple Form Analogy* and *Complex Form Analogy*.

# Study 2

The conditions in study 2 continue to abstract from a representational
symbol-referent relationship by using different shapes for both cue and
target stimuli. The conditions here, draw on gestalt-principles like
figure-ground-relationship, continuity and parallelism. The
symbol-referent-relationship in *Absolute Position* is established by
the respective cue and target sharing the same position with regard to
the reference frame they occur in. In *Relative Position* cue and target
are each composed of two shapes. Reference is established by the
respective shapes being closer or further apart or sharing a position on
a horizontal or vertical axis. For *Orientation of Object*, symbol and
cue are aligned along the same axis. The final condition, *Orientation
of Feature* employs cue and target shapes with a salient feature that is
either oriented up- or downward. The preregistered hypothesis, assumed
children to perform above chance first in *Orientation of Object*, then
*Orientation of Feature*, *Absolute Position* and finally *Relative
Position*.

## Stimuli

For comparability, *Absolute Position* and *Relative Position* employed
the same distinct shapes as cue and target respectively (circle vs.
square, cross). In *Absolute Position* target positions were placed in
top and bottom, or central and peripheral conditions in half of trails.
For *Relative Position*, two trials present target stimuli that are
closer together or further apart, as well as another two trials with
target components being aligned on a horizontal or vertical axis. To
ensure that cue and target are maximally distinct in all dimensions,
cues and target items do not allign on the same axxis. As in study 1,
cues and targets are either round and rectangular shapes in these
conditions. To convey a sense of direction in *Orientation of Object,*
cues and targets feature elongated shapes that are aligned either on a
horizontal, vertical, or diagonal axis with rising or falling slope. The
shapes are distinct oblong elipses and rectangles or abstract shapes
with more or less round or square features. For *Orientation of
Feature*, targets and cues are either circles or squares with a salient
feature like an opening or a dent. While these shapes and features
alternate for the related cue and target, they are aligned up- or
downwards. As in study 1, cues in *Orientation of Feature* were oriented
on a vertical axis, to counter interpretations as arrow-like cues
[@kachelarrowsInPrep]. For an overview of all stimuli per condition in
Study 2, see figure \@ref(fig:suppl-plot-S2-stimuli) [MB: siehe oben, vll ins paper mit rein] in appendix B.

## Participants

A total of `r rep.age.table.data["study2", "N"]` three- to
seven-year-old children (M = `r rep.age.table.data["study2", "Mean"]`
months, SD = `r rep.age.table.data["study2", "SD"]` months, range
`r rep.age.table.data["study2", "Min"]` -
`r rep.age.table.data["study2", "Max"]` months;
`r rep.age.table.data["study2", "female"]` female) participated. In
addition, a total of `r rep.drop.table.data["study2", "N"]` children
(`r rep.drop.table.data["study2", "female"]` female) were tested but
excluded from analysis for failing familiarization (N =
`r rep.drop.table.data["study2", "fail_in_fam"]`), being fussy (N =
`r rep.drop.table.data["study2", "fussy_child"]`), not being fluent
enough in German to follow the instructions (N =
`r rep.drop.table.data["study2", "language"]`), or due to technical
issues (N = `r rep.drop.table.data["study2", "technical"]`).

## Analysis

A total of `r sum(rep.s2.trials$Trials)` trials (mean per condition =
`r mean(rep.s2.trials$Trials)`, range: `r min(rep.s2.trials$Trials)` -
`r max(rep.s2.trials$Trials)`) from
`r rep.age.table.data["study2", "N"]` participants were submitted for
analysis. The full model notation was
`correct ~ condition*z.age + z.trial + sex + (z.trial | subid)`. In
addition, a null model lacking the interaction of condition and age was
fitted.

## Results

For both full and null model, PPCs indicate excellent fit of observed
data and model predictions. To compare model performance, we evaluated
the WAIC estimates. The null model showed a slightly better predictive
performance (ELPD = `r round(S2.comp["S2.null.bm","elpd_waic"],2)`)
compared to the full model (ELPD =
`r round(S2.comp["S2.full.bm","elpd_waic"],2)`). WAIC values also
indicate better performance of the null model (WAIC =
`r round(S2.comp["S2.null.bm", "waic"],2)`) over the full model (WAIC =
`r round(S2.comp["S2.full.bm", "waic"],2)`). However, the difference
between models (ELPD Diff =
`r round(S2.comp["S2.full.bm", "elpd_diff"],2)`) falls within the bounds
of uncertainty (SE = `r round(S2.comp["S2.full.bm", "se_diff"],2)`),
suggesting no advantage in predictive accuracy. Hence, the preregistered
analyses using the full model is reported below.

Across all conditions, performance improved with both age ($\beta$ =
`r S2.full.coef["z.age", "mean"]`, 95% CrI
[`r S2.full.coef["z.age", "q2.5"]`, `r S2.full.coef["z.age", "q97.5"]`)
and slightly with trial number ($\beta$ =
`r S2.full.coef["z.trial", "mean"]`, 95% CrI
[`r S2.full.coef["z.trial", "q2.5"]`,
`r S2.full.coef["z.trial", "q97.5"]`). Relative to *Absolute Position*,
children were generally less likely to correctly solve *Relative
Position* ($\beta$ = `r S2.full.coef["RelativePosition", "mean"]`, 95% CrI
[`r S2.full.coef["RelativePosition", "q2.5"]`,
`r S2.full.coef["RelativePosition", "q97.5"]`). Performance in
*Orientation of Object* ($\beta$ =
`r S2.full.coef["OrientationofObject", "mean"]`, 95% CrI
[`r S2.full.coef["OrientationofObject", "q2.5"]`,
`r S2.full.coef["OrientationofObject", "q97.5"]`) and *Orientation of
Feature* ($\beta$ = `r S2.full.coef["OrientationofFeature", "mean"]`, 95%
CrI [`r S2.full.coef["OrientationofFeature", "q2.5"]`,
`r S2.full.coef["OrientationofFeature", "q97.5"]`) was not substantially
different from the reference category when considering the full age
range. Interaction terms between age and condition were not credibly
different from zero, suggesting similar developmental patterns for all
conditions. Tracing the lower bound of the 95% CrI against the 50%
chance level (cf. figure \@ref(fig:plot-study2)), the model establishes
that children master the condition *Absolute Position* at
`r p2$months[p2$condition == "Absolute Position"]` months, making it the
easiest task in study 2. Then in quick succession, children succeed in
*Orientation of Feature* at
`r p2$months[p2$condition == "Orientation of Feature"]` months,
*Relative Position* at
`r p2$months[p2$condition == "Relative Position"]` months and
*Orientation of Object* at
`r p2$months[p2$condition == "Orientation of Object"]` months. For a
side-by-side comparison of the developmental trajectories, see figure
\@ref(fig:plot-study2). For an additional conventional analysis binning
participants according to their age in years, see table
\@ref(tab:suppl-descriptives-S2) in appendix C. See appendix C table
\@ref(tab:suppl-S2-coef-table) and table
\@ref(tab:suppl-descriptives-S2) for an overview of model coefficients.

```{r plot-study2, fig.cap = "*Developmental Trajectories for all Conditions in Study 2.* Panels illustrate example stimulus combinations (distractor, cue, target) and results for all conditions. Coloured lines indicate smoothed mean performance by age. Shaded areas represent 95% CrIs. The dashed line demarcates chance level and the dots represent individual means. The coloured dots and annotation indicate when performance exceeds chance level.", fig.align = "center", echo = FALSE, out.width = "100%"}

knitr::include_graphics(knitr::plot_crop("../illustrations/plot_study2.png"))

```

## Discussion

We hypothesized that children as a group would perform above chance
earlier with *Absolute Position* than with *Relative Position* due to
the latter obviously requiring children to integrate a higher number of
items. Results confirm this assumption with a clear 5-months offset in
the age of success. We hypothesized further that children would succeed
earlier with *Orientation of Object* than *Orientation of Feature*, due
to the necessity of evaluating the composition of a target item rather
than its general alignment with the cue. Here, we find the opposite to
be true. The impression of direction or congruence between cue and
target appears to be much more salient for children in graphic stimuli
with a salient feature pointing out such as in *Orientation of Feature*,
than an overall alignment in the horizontal, vertical or diagonal
orientation. However, an overall picture emerges from the results of
study 2: with stimuli that are not primarily drawing on representational
symbol-referent relationships but that are based in more conceptual
Gestalt principles, children generally come to perform above chance
closely around the fourth birthday. Arguably, all four of these
conditions still have an iconic aspect to them with regard to the
overall gestalt of the displays. Study 3 set out to further reduce the
amount of iconicity and investigate fully abstract symbol-referent
relationships.

# Study 3

The final study features symbol-referent relationships that are based on
analogies in size or number without cues and targets sharing
similarities in other visual aspects, and while avoiding to draw on
conventions in graphic communication. In order to correctly interpret
the symbol-referent relationships employed here, children need to assign
or extract conceptual order in graphical displays. Such processes can be
fostered or obstructed by surface level features of the stimuli at hand
which makes it harder to assess whether the age at which children master
a task - our primary aim of investigation - depends more on the ability
to generally form symbol-referent relationships from analogies or from
children's developing ability to process visual complexity. The two base
conditions of study three are *Size of Object* and *Size of Number.*
Here the cues refer to a target shape as a whole via an analogy in size
or number. They are complemented by the conditions *Size of Feature* and
*Number of Feature* in which the cues refer to a salient aspect of the
target stimuli. In these cases, extracting conceptual information is
arguably more demanding. The overall performance across the ages as well
as the relative offset in the age at which children solve a task based
on symbol-referent relationships targeting objects or their features,
can then serve to evaluate such surface-level effects across two
different domains. Prior to data collection, we hypothesized that
children will succeed earlier with symbol-referent relationships based
in size than in number, and that children will succeed earlier when cues
refer to a target object per se rather than a salient feature thereof.

## Stimuli

In *Size of Object* the targets in a each trial are identical shapes
that are either small or large with regard to the reference frame they
are presented in. To make cue and target shapes as distinct as possible
they are again employing either squares or circles respectively or fully
abstract shapes such as a random scribble or straight lines (cf. figure
\@ref(fig:suppl-plot-S3-stimuli), A). For comparability, *Size of
Feature* employs the exact same cues as *Size of Object*, but features
target shapes with either a relatively large or small void, opening, or
protrusion. In *Number of Object*, cues and targets are composed of
different shapes with some being simple line drawings. The displayed
quantities were one against three, and two against four. As such they
are easy to grasp and distinguish even for young children [MB: reference would be nice here]. Special
attention was paid to the arrangement of the objects to ensure that the
cue and target objects do not share visually similarity by forming a
similar pattern, which is difficult as such small number arrays lend
themselves to being grouped into canonical shapes by Gestalt principles
such as proximity and closure. This issue was addressed by presenting
the targets depicting the magnitudes three and four as if outlining
irregular shapes. By contrast, the corresponding cues were aligned along
a vertical of horizontal axis. For comparability, *Number of Feature*
employs the same cues as *Number of Object*. To evoke a sense of
quantity in the closed forms serving as referents, the target shapes in
*Number of Feature* either have salient protrusions, or partial areas
resulting from incisions. For an overview of all stimuli presented in
Study 3, see figure \@ref(fig:suppl-plot-S3-stimuli) in appendix B.

## Participants

A total of `r rep.age.table.data["study3", "N"]` three- to
seven-year-old children (M = `r rep.age.table.data["study3", "Mean"]`
months, SD = `r rep.age.table.data["study3", "SD"]` months, range
`r rep.age.table.data["study3", "Min"]` -
`r rep.age.table.data["study3", "Max"]` months;
`r rep.age.table.data["study3", "female"]` female) participated. In
addition, `r rep.drop.table.data["study3", "N"]` children
(`r rep.drop.table.data["study3", "female"]` female) were tested but
excluded for low performance during familiarization (N =
`r rep.drop.table.data["study3", "fail_in_fam"]`), for not completing at
least eight out of 16 test trials (N =
`r rep.drop.table.data["study3", "quit_early"]`), or being fussy (N =
`r rep.drop.table.data["study3", "fussy_child"]`). Further exclusions
were necessary due to language problems (N =
`r rep.drop.table.data["study3", "language"]`) and technical issues (N =
`r rep.drop.table.data["study3", "technical"]`).

## Analysis

For study three, `r sum(rep.s3.trials$Trials)` trials (mean per
condition = `r mean(rep.s3.trials$Trials)`, range:
`r min(rep.s3.trials$Trials)` - `r max(rep.s3.trials$Trials)`) from
`r rep.age.table.data["study3", "N"]` participants were submitted for
analysis. Data were analyzed both with a full model
(`correct ~ condition*z.age + z.trial + sex + (z.trial | subid)`) and a
null model lacking the interaction of condition and age.

## Results

PPCs indicated excellent fit of observed data and model predictions in
both models. When comparing performance, the full model showed a better
fit (ELPD = `r round(S3.comp["S3.full.bm","elpd_waic"],2)`) relative to
the null model (ELPD = `r round(S3.comp["S3.null.bm","elpd_waic"],2)`).
The WAIC values also favored the full model (WAIC =
`r round(S3.comp["S3.full.bm", "waic"],2)`) over the null model (WAIC =
`r round(S3.comp["S3.null.bm", "waic"],2)`). Despite the slightly lower
WAIC and higher ELPD of the full model, the difference in predictive
accuracy (ELPD Diff = `r round(S3.comp["S3.null.bm", "elpd_diff"],2)`)
remains almost within the range of sampling uncertainty (SE =
`r round(S3.comp["S3.null.bm", "se_diff"],2)`). In the absence of
substantial differences, the full model is reported below in line with
the preregistration.

Overall, children's performance increased with age ($\beta$ =
`r S3.full.coef["z.age", "mean"]`, 95% CrI
[`r S3.full.coef["z.age", "q2.5"]`, `r S3.full.coef["z.age", "q97.5"]`)
and with trial number ($\beta$ = `r S3.full.coef["z.trial", "mean"]`, 95%
CrI [`r S3.full.coef["z.trial", "q2.5"]`,
`r S3.full.coef["z.trial", "q97.5"]`), indicating general improvement
across development and time-on-task. Relative to *Size of Object*,
participants were substantially less accurate in *Size of Feature* (beta
= `r S3.full.coef["SizeofFeature", "mean"]`, 95% CrI
[`r S3.full.coef["SizeofFeature", "q2.5"]`,
`r S3.full.coef["SizeofFeature", "q97.5"]`). A smaller, marginal effect
was observed in *Number of Feature* ($\beta$ =
`r S3.full.coef["NumberofFeature", "mean"]`, 95% CrI
[`r S3.full.coef["NumberofFeature", "q2.5"]`,
`r S3.full.coef["NumberofFeature", "q97.5"]`). *Number of Object* (beta
= `r S3.full.coef["NumberofObject", "mean"]`, 95% CrI
[`r S3.full.coef["NumberofObject", "q2.5"]`,
`r S3.full.coef["NumberofObject", "q97.5"]`) did not differ reliably
from *Size of Object*. Age moderated performance less strongly in *Size
of Feature* ($\beta$ = `r S3.full.coef["SizeofFeature:z.age", "mean"]`) and
*Number of Feature* ($\beta$ =
`r S3.full.coef["NumberofFeature:z.age", "mean"]`) [MB: warum kein 95% CRI hier], suggesting lower
developmental gains compared to *Size of Object*. Generally, the
conditions relying on feature-based reference are associated with lower
overall performance and weaker developmental gains. The best overview of
the relative performance across conditions is provided by plotting the
model estimates (cf. figure \@ref(fig:plot-study3)). Children succeed in
most conditions just after the fourth birthday. Model estimates indicate
group level success in *Size of Object* at
`r p3$months[p3$condition == "Size of Object"]` months, *Number of
Object* at `r p3$months[p3$condition == "Number of Object"]` months, and
*Number of Feature* at
`r p3$months[p3$condition == "Number of Feature"]` months. The exception
to this pattern is *Size of Feature* where children master the task no
sooner than `r p3$months[p3$condition == "Size of Feature"]` months of
age. For an overview of model coefficients see table table
\@ref(tab:suppl-S3-coef-table), appendix C. For alternative analyses
binning children by year of age, please see table
\@ref(tab:suppl-descriptives-S3) (ibid).

```{r plot-study3, fig.cap = "*Developmental Trajectories for all Conditions in Study 3.* Panels illustrate example stimulus combinations (distractor, cue, target) and results. Coloured lines indicate smoothed mean performance by age. Shaded areas represent 95% CrIs. The dashed line demarcates chance level and the dots represent individual means. The coloured dots and annotation indicate when performance exceeds chance level.", fig.align = "center", echo = FALSE, out.width = "100%"}

knitr::include_graphics(knitr::plot_crop("../illustrations/plot_study3.png"))

```

## Discussion

We hypothesized that children will succeed earlier with analogies in
size than in number, and that children will succeed earlier when cues
refer to the target objects per se rather than salient features thereof.
We find limited support for the hypothesis that the feature conditions
are generally more demanding. However, that children succeed a month
earlier in *Number of Object* than in *Size of Object* as hypothesized
is negligible especially in the context of the four year age-range that
is considered here. Taken together the results may better be interpreted
as further indicating that children are solving analogy-based
symbol-referent relationships just after the fourth birthday, as if -
provided that a critical level of reasoning development is attained -
children can generally dismiss surface level features and focus on
conceptional dimensions [@gentner1988metaphor; @richland2006children]
and flexibly employ their analogical reasoning skills in communicative
contexts regardless of the specific conceptual dimensions such as number
or size.

The late success at 59 months in *Size of Feature* is slightly
ambiguous. *Size of Feature* stands out as the most difficult condition
in the series of studies presented here and is definitely quite
demanding as it is a highly conceptual symbol-referent relationship and
the only condition that requires children to consider proportions within
the composition of the target stimulus. However, given that the
developmental trajectory is quite flat and the CrI comparably wide, the
operationalization or graphical implementation of the concept *Size of
Feature* may simply not have been ideal and salient enough [MB: würde ich vll nochmal gucken ob Du eine inhaltlicher erklärung findest - 1. weil die Stimuli sehr sorgfältig kreiert wurden und 2. weil das alle anderen ergebnisse auch in Frage stellt (könnte ja auch sein, dass die stimuli eher schwer waren und wir daher alles unterschätzen).]. *Size of
Object* demonstrates that children generally can grasp form analogies
earlier with the exact same cues and *Absolute Position* and *Relative
Position* from study 2 indicate that children can also master
figure-ground relationships or relational patterns in targets even prior
to the fourth birthday. It is reasonable to assume that children could
succeed slightly earlier in *Size of Feature* if the opening or bumps
representing the size relationship in the target displays would simply
be more pronounced.

# Additional Analyses

??? Ich würde erstmal alles weitere fertig machen und die Additional
Analyses optional lassen ??? [MB: ja, gute Idee]

Preregistration: \*An additional exploratory analysis will include a
random effect for item level effects (Model: correct \~ task*z.age
+z.trial +z.sex +(z.trial\|id) +(z.age\|item)). Results will help to
evaluate the equivalence of items within a task and be reported in the
supplements. Due to the low number of individual items within a task we
expect this model to be less diagnostic with regard to our main research
question and, therefore, will not include the term in the main
analysis.* [MB: Ich würde die models auf jeden Fall laufen lassen wenn wir sie in der der pre-reg haben und dann einfach sagen: macht keinen großen unterschied.]

# Discussion

not ready yet...

[See googledocs for intro and
discussion.](https://docs.google.com/document/d/1nLlkREwo1JXngqy9Dfyhx5kdV4ue9w0fRJ61O8gDNIc/edit?usp=sharing)

<!-- RESTE ...Backup von alten Versionen -->

<!-- RESTE ...Backup von alten Versionen -->

<!-- RESTE ...Backup von alten Versionen -->

```{r rep_S1_bayes_fullmodel_plotting_sketch, echo=FALSE, eval=F, warning = F, message=F}
# packages -----------
# library(patchwork)
# library(magick)
# library(grid)
# library(ggplotify)
# library(dplyr)
# library(ggplot2)
# library(magick)

library(cowplot)

# creating plots -------------------------------------

# Get the selected condition level
this_condition <- levels(d1$condition)[1]
# Create the plot
plot_1 <- ggplot() +
  geom_hline(yintercept = .5, lty = 2, alpha = .75) +
  
  geom_point(data = d1 %>% filter(condition == this_condition), 
             aes(x = ageinyears, y = mean, col = I(colour)), alpha = .5, shape = 1) +
  
  geom_smooth(data = f1 %>% filter(condition == this_condition),
              aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, 
                  fill = I(colour), col = I(colour)),
              stat = "identity", alpha = .25) +
  
  geom_point(data = p1 %>% filter(condition == this_condition),
             aes(x = days/365.25, y = .5, fill = I(colour), col = I(colour)), 
             stat = "identity", size = 3) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = months, x = days/365.25, y = .24, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = "months", x = days/365.25, y = .38, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  theme_minimal() +
  ylim(0, 1) +
  xlim(3, 7) +
  labs(y = "Proportion Correct") +
  theme(
    # axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    # axis.text.y = element_blank(),
    legend.position = "none")

# Get the selected condition level
this_condition <- levels(d1$condition)[2]
# Create the plot
plot_2 <- ggplot() +
  geom_hline(yintercept = .5, lty = 2, alpha = .75) +
  
  geom_point(data = d1 %>% filter(condition == this_condition), 
             aes(x = ageinyears, y = mean, col = I(colour)), alpha = .5, shape = 1) +
  
  geom_smooth(data = f1 %>% filter(condition == this_condition),
              aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, 
                  fill = I(colour), col = I(colour)),
              stat = "identity", alpha = .25) +
  
  geom_point(data = p1 %>% filter(condition == this_condition),
             aes(x = days/365.25, y = .5, fill = I(colour), col = I(colour)), 
             stat = "identity", size = 3) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = months, x = days/365.25, y = .24, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = "months", x = days/365.25, y = .38, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  theme_minimal() +
  ylim(0, 1) +
  xlim(3, 7) +
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    legend.position = "none")

# Get the selected condition level
this_condition <- levels(d1$condition)[3]
# Create the plot
plot_3 <- ggplot() +
  geom_hline(yintercept = .5, lty = 2, alpha = .75) +
  
  geom_point(data = d1 %>% filter(condition == this_condition), 
             aes(x = ageinyears, y = mean, col = I(colour)), alpha = .5, shape = 1) +
  
  geom_smooth(data = f1 %>% filter(condition == this_condition),
              aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, 
                  fill = I(colour), col = I(colour)),
              stat = "identity", alpha = .25) +
  
  geom_point(data = p1 %>% filter(condition == this_condition),
             aes(x = days/365.25, y = .5, fill = I(colour), col = I(colour)), 
             stat = "identity", size = 3) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = months, x = days/365.25, y = .24, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = "months", x = days/365.25, y = .38, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  theme_minimal() +
  ylim(0, 1) +
  xlim(3, 7) +
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    legend.position = "none")



# Get the selected condition level
this_condition <- levels(d1$condition)[4]
# Create the plot
plot_4 <- ggplot() +
  geom_hline(yintercept = .5, lty = 2, alpha = .75) +
  
  geom_point(data = d1 %>% filter(condition == this_condition), 
             aes(x = ageinyears, y = mean, col = I(colour)), alpha = .5, shape = 1) +
  
  geom_smooth(data = f1 %>% filter(condition == this_condition),
              aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, 
                  fill = I(colour), col = I(colour)),
              stat = "identity", alpha = .25) +
  
  geom_point(data = p1 %>% filter(condition == this_condition),
             aes(x = days/365.25, y = .5, fill = I(colour), col = I(colour)), 
             stat = "identity", size = 3) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = months, x = days/365.25, y = .24, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  
  geom_text(data = p1 %>% filter(condition == this_condition),
            aes(label = "months", x = days/365.25, y = .38, 
                fill = I(colour), col = I(colour)), 
            angle = 90, size = 4, parse = TRUE) +
  theme_minimal() +
  ylim(0, 1) +
  xlim(3, 7) +
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    legend.position = "none")

# loading images ---------------

image_1  <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[1], ".png")) 
image_2 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[2], ".png")) 
image_3 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[3], ".png")) 
image_4 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[4], ".png")) 


# combining things -----------

plots_1234 <- plot_grid(plot_1, plot_2, plot_3, plot_4,
                        nrow =1, align = 'h')
plot_S1 <- ggdraw() + 
  draw_plot(plots_1234, 0, 0, 1, 0.75) +  # Plot takes lower 80% of canvas
  
  draw_image(image_1, x = 0.03, y = 0.6, width = 0.22, height = 0.4) +
  draw_image(image_2, x = .265, y = 0.6, width = 0.22, height = 0.4) +
  draw_image(image_3, x = .513, y = 0.6, width = 0.22, height = 0.4) +
  draw_image(image_4, x = .762, y = 0.6, width = 0.22, height = 0.4) +  
  
  draw_label(levels(d1$condition)[1], x = 0.147, y = .94, fontface = "bold", size = 14, hjust = 0.5) +
  draw_label(levels(d1$condition)[2], x = 0.375, y = .94, fontface = "bold", size = 14, hjust = 0.5) +
  draw_label(levels(d1$condition)[3], x = 0.632, y = .94, fontface = "bold", size = 14, hjust = 0.5) +
  draw_label(levels(d1$condition)[4], x = 0.88, y = .94, fontface = "bold", size = 14, hjust = 0.5)

plot_S1


```

```{r rep_S1_bayes_fullmodel_plotting_new2904, echo=FALSE, eval=F, warning = F, message=F}

# library(ggplot2)
library(png)
library(grid)
# while (!is.null(dev.list())) dev.off()

# main plot -----
# library(ggplot2)
# library(png)
library(grid)
# while (!is.null(dev.list())) dev.off()

# Step 1: Load the image file (PNG)
img <- readPNG("../illustrations/plotexample Pars pro Toto.png")
img_grob <- rasterGrob(img, interpolate = TRUE)

# Step 2: Create main plot
main_plot <- ggplot() +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey70", alpha = 0.75) +
  
  geom_point(data = d1, aes(x = ageinyears, y = mean, colour = colour), alpha = 0.5, shape = 1, size = 2) +
  
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = colour, colour = colour),
              stat = "identity", alpha = 0.2, linewidth = 0.8) +
  
  geom_point(data = p1, aes(x = days/365.25, y = 0.5, fill = colour, colour = colour), size = 4, shape = 21, stroke = 1) +
  geom_point(data = p1, aes(x = days/365.25, y = 0.5, fill = "black", colour = "black"), size = 0.5, shape = 21, stroke = 1) +
  geom_text(data = p1, aes(label = months, x = days/365.25, y = 0.24, colour = "black"),
            angle = 90, size = 3.2, vjust = 0.5) +
  
  geom_text(data = p1, aes(label = "months", x = days/365.25, y = 0.38, colour = "black"), 
            angle = 90, size = 3.2, vjust = 0.5) +
  
  scale_colour_identity() +
  scale_fill_identity() +
  scale_y_continuous(labels = function(x) paste0(x*100, "%")) + # Multiply by 100 & add %  
  
  
  facet_grid(cols = vars(condition)) +
  
  labs(x = "Age", y = "Proportion correct") +
  
  coord_cartesian(ylim = c(0, 1), xlim = c(2.7, 7.3)) +   # Allow more Y space for image
  
  theme_minimal(base_size = 13) +
  theme(
    panel.border = element_rect(colour = "grey30", fill = NA, size = 0.8),
    strip.background = element_rect(colour = "grey30", size = 0.8),
    strip.text = element_text(face = "bold", size = rel(0.8), 
                              margin = margin(t = 5, b = 45)),
    strip.switch.pad.grid = unit(0, "cm"),
    axis.title = element_text(face = "bold", size = rel(0.8)),
    axis.text = element_text(size = rel(0.8)),
    legend.position = "none",
    panel.grid.minor = element_blank()
  )

# adding images -----
# load images
image_1 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[1], ".png")) 
image_2 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[2], ".png")) 
image_3 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[3], ".png")) 
image_4 <- image_read(paste0("../illustrations/plotexample ", levels(d1$condition)[4], ".png")) 
# create grobs
image_1_grob <- rasterGrob(image_1, interpolate = TRUE)
image_2_grob <- rasterGrob(image_2, interpolate = TRUE)
image_3_grob <- rasterGrob(image_3, interpolate = TRUE)
image_4_grob <- rasterGrob(image_4, interpolate = TRUE)


# place images on the plot
library(cowplot)

final_plot <- ggdraw(main_plot) +
  draw_grob(image_1_grob, x = 0.08, y = 0.78, width = 0.23, height = 0.13) +
  draw_grob(image_2_grob, x = 0.31, y = 0.78, width = 0.23, height = 0.13) +
  draw_grob(image_3_grob, x = 0.54, y = 0.78, width = 0.23, height = 0.13) +
  draw_grob(image_4_grob, x = 0.77, y = 0.78, width = 0.23, height = 0.13)

# Save  ------------
ggsave(
  filename = "../illustrations/final_plot.png",
  plot = final_plot,   # <- IMPORTANT: plot = main_plot
  device = "png",
  width = 8, height = 4,
  dpi = 300,
  units = "in",
  bg = "white"
)

# display plot
img <- image_read("../illustrations/study1_plot.png")

windows(width = 15, height = 10)  # On Windows
plot(img)

```

```{r rep_S1_bayes_fullmodel_plotting, echo=FALSE, eval=F, warning = F, message=F}


# side by side
ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill = condition, col = condition),
              stat = "identity", alpha = .25)+
  geom_point(data = p1, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size = 3)+
  geom_text(data = p1, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle = 90, size = 4, parse = TRUE)+
  geom_text(data = p1, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle = 90, size = 4, parse = TRUE)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(cols = vars(condition))+
  labs(x = "Age", y = "Proportion correct")+
  ylim(0, 1)+
  xlim(3, 7)+
  theme(legend.position = "bottom")
```

```{r S2_bayes_fullmodel, echo=FALSE, include=F, eval=F}


# S2.full.bm<-brm(correct~condition+z.age+(1|subid), 
#                data=rep.S2.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)
# 

S2.null.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S2.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S2.null.bm <- add_criterion(S2.null.bm, c("loo", "waic"))

S2.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S2.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S2.full.bm <- add_criterion(S2.full.bm, c("loo", "waic"))

S2.comp <- loo_compare(S2.null.bm, S2.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S2.weights <- model_weights(S2.null.bm, S2.full.bm, criterion = "waic") %>% as_tibble(rownames = "index")

# 
# loo_compare(S2.null.bm, S2.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
# model_weights(S2.null.bm, S2.full.bm, criterion = "waic")

# Saving the model (to not rerun it every time)

### LOO COMPARISON
### not reported, essentially identical
# S2.null.loo <- loo(S2.null.bm)
# S2.full.loo <- loo(S2.full.bm)
# S2.loo.comp <- loo_compare(S2.null.loo, S2.full.loo) %>%
#   as_tibble(rownames = "model")
# S2.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S2.full.bm, "../models/S2.full.bm.rds")
saveRDS(S2.null.bm, "../models/S2.null.bm.rds")
saveRDS(S2.comp, "../models/S2.comp.rds")
saveRDS(S2.weights, "../models/S2.weights.rds")





```

```{r S2_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=F}

# load model from saving rds
S2.full.bm <- readRDS("../models/S2.full.bm.rds")

nd2 <- tibble(z.age = rep(seq(from = min(rep.S2.bayes.data$z.age), 
                              to = max(rep.S2.bayes.data$z.age), 
                              length.out = 50),4),
             condition = c(rep("Relative Position",50), 
                           rep("Absolute Position",50), 
                           rep("Orientation of Feature",50), 
                           rep("Orientation of Object",50)), # the four conditions in the data
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f2 <- fitted(S2.full.bm, 
             newdata = nd2, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd2)%>%
  mutate(age = z.age + mean(rep.S2.bayes.data$ageinyears)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d2 <- rep.S2.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct))

```

```{r S3_bayes_fullmodel, echo=FALSE, include=F, eval=F}


S3.null.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S3.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S3.null.bm <- add_criterion(S3.null.bm, c("loo", "waic"))

S3.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S3.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))

S3.comp <- loo_compare(S3.null.bm, S3.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S3.weights <- model_weights(S3.null.bm, S3.full.bm, criterion = "waic") %>% as_tibble(rownames = "index")

### LOO COMPARISON
### not reported, essentially identical
# S2.null.loo <- loo(S2.null.bm)
# S2.full.loo <- loo(S2.full.bm)
# S2.loo.comp <- loo_compare(S2.null.loo, S2.full.loo) %>%
#   as_tibble(rownames = "model")
# S2.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S3.full.bm, "../models/S3.full.bm.rds")
saveRDS(S3.null.bm, "../models/S3.null.bm.rds")
saveRDS(S3.comp, "../models/S3.comp.rds")
saveRDS(S3.weights, "../models/S3.weights.rds")

# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)
# 
# S3.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
#                 data= rep.S3.bayes.data, 
#                 family=bernoulli(),
#                 chains = 4,
#                 iter= 2000,
#                 cores= 4)
# 
# S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))
# 
# # Saving the model (to not rerun it every time)
# saveRDS(S3.full.bm, "../models/S3.full.bm.rds")

```

```{r S3_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=F, warning=F, message=F}

# load model from saving rds
S3.full.bm <- readRDS("../models/S3.full.bm.rds")

nd3 <- tibble(z.age = rep(seq(from = min(rep.S3.bayes.data$z.age), 
                              to = max(rep.S3.bayes.data$z.age), 
                              length.out = 50),4),
             condition = c(rep("Number of Object",50), 
                           rep("Number of Feature",50), 
                           rep("Size of Object",50), 
                           rep("Size of Feature",50)),
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f3 <- fitted(S3.full.bm, 
             newdata = nd3, 
             re_formula = NA) %>% 
  as_tibble() %>%
  bind_cols(nd3)%>%
  mutate(age = z.age + mean(rep.S3.bayes.data$ageinyears)) 


# summarize the data to include them in the plot later on
d3 <- rep.S3.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) 

```

```{r S1_bayes_plot_no_facets, echo=FALSE, eval=F, warning = F, message=F}

# Plot without facetting

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

```{r S1_bayes_plot, echo=FALSE, eval=F, warning = F, message=F}

p1 <- f1 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

S1_plot <- ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

#
S1_plot

```

```{r S2_bayes_plot, echo=FALSE, eval=F, warning=F, message=F}

p2 <- f2 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

```

```{r S2_mixbayes_plot, echo=FALSE, eval=F, warning=F, message=F}


p2 <- f2 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

```

```{r S3_bayes_plot, echo=FALSE, eval=F, warning=F, message=F}

# Plot without facetting
p3 <- f3 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months")))

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")




```

```{r S3_mixbayes_plot, echo=FALSE, eval=F, warning=F, message=F}

p3 <- f3 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months")))

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

<!-- RESTE ...Backup von alten Versionen -->

<!-- RESTE ...Backup von alten Versionen -->

<!-- RESTE ...Backup von alten Versionen -->

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::

```{r, eval =FALSE}
# (APPENDIX) Appendix {-}

```

\newpage

```{r child = "appendix_a_participants.Rmd"}
```

\newpage

```{r child = "appendix_b_stimuli.Rmd"}
```

\newpage

```{r child = "appendix_c_descriptives.Rmd"}
```

\newpage

```{r child = "appendix_d_diagnostics.Rmd"}
```

\newpage

```{r child = "appendix_e_additional.Rmd"}
```
