---
title             : "Young children’s spontaneous comprehension of symbol-object-relationships in the graphic domain"
shorttitle        : "Comprehension of symbol-object-relationships"

author: 
  - name          : "Gregor Kachel"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Universitätsallee 1, C1.008a, 21335 Lüneburg"
    email         : "gregor.kachel&#64;leuphana.de"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Funding Acquisition"
      - "Project Administration"
      - "Investigation"
      - "Methodology"
      - "Data Curation"
      - "Formal Analysis"
      - "Visualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Daniel Haun"
    affiliation   : "2"
    role:
      - "Resources"
      - "Writing - Review & Editing"
  - name          : "Manuel Bohn"
    affiliation   : "1"
    role:
      - "Methodology"
      - "Software"
      - "Formal Analysis"
      - "Validation"
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Leuphana University"
  - id            : "2"
    institution   : "Max-Planck-Institute for Evolutionary Anthropology"
authornote: |
    *Ethics, consent and conflict of interest*: This study confirms with recognized standards (e.g. the Declaration of Helsinki) and was approved by an internal ethics committee at the Max-Planck-Institute for Evolutionary Anthropology. Informed consent has been obtained from all participants. The authors declare no conflict of interest. 
    
    *Acknowledgments*: We are thankful to Susanne Mauritz for her help in the organization of the study and to Valerie Jurgenson and Cynthia Pones for help with data collection. We would like to thank Anne Deiglmayr for hosting this project in her research group and for her continuous support. Finally, we are very thankful to all parents and children participating in the study. Gregor Kachel was supported by the German Research Foundation (Deutsche Forschungsgemeinschaft) under project number 429220405.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  One or two sentences to put the results into a more **general context**.
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline. Abstract must be less then 120words
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "graphical representation, iconicity, analogy, symbol, communication, emerging literacy"
wordcount         : "Child Development Max 40 pages // PNAS 1,500–2,000 words"

bibliography      : ["library.bib"]

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine: xelatex

appendix: # to change filenames, also see end of document
- "appendix_a_participants.Rmd"
- "appendix_b_stimuli.Rmd"
- "appendix_c_descriptives.Rmd"
- "appendix_d_diagnostics.Rmd"
- "appendix_e_additional.Rmd"

    
---
```{r setup, include = FALSE}
library("papaja")
r_refs("library.bib")

# Loading packages 
# NOTE: this will install these packages on your machine in case they are missing

# General
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
if (!require(lsr)) install.packages('lsr'); library(lsr) # Analysis, Cohen's D
if (!require(ggthemes)) install.packages('ggthemes'); library(ggthemes) # for tufte boxplots
if (!require(kableExtra)) install.packages('kableExtra'); library(kableExtra) 

# bayes packages
if (!require(brms)) install.packages('brms'); library(brms) # 
if (!require(tidybayes)) install.packages('tidybayes'); library(tidybayes) # 
if (!require(HDInterval)) install.packages('HDInterval'); library(HDInterval) # 
if (!require(posterior)) install.packages('posterior'); library(posterior) # 

# basic analyses
if (!require(scales)) install.packages('scales'); library(scales) # 

# Troubleshooting Knitting Document
# might be required for knitting manuscript
# install.packages('tinytex')
# tinytex::install_tinytex()
# 
# tinytex::tlmgr_update()
# tinytex::reinstall_tinytex()

```

```{r analysis_preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

```

```{r rep_read_data, include = FALSE}

# Full data set including all participants (i.e. including dropped participants)
rep.data <- readRDS("../data/symlitrep_final_data.rds")

# test  <- rep.data %>%
#   #filter(valid != "drop") %>% # valid participants only 
#   filter(trial != "fam") %>% 
#   group_by(subid, agem) %>% 
#   summarize(participants = n_distinct(subid),
#             trials = n())

# Study1 
rep.S1.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study1") %>% # in study one
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Representation", # first level becomes reference
        "Pars Pro Toto", 
        "Simple Form Analogy", 
        "Complex Form Analogy"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# Study2
rep.S2.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study2") %>% # in study two
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Absolute Position", # first level becomes reference
        "Relative Position", 
        "Orientation of Object", 
        "Orientation of Feature"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# Study 3 
rep.S3.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study3") %>% # in study two
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, agey, agem, correct, trial, rt, cue) %>%
  mutate(condition = factor(condition, levels = c(
        "Size of Object", # first level becomes reference
        "Size of Feature", 
        "Number of Object", 
        "Number of Feature"))) %>%  
  mutate(sex = factor(sex, levels = c(
        "0", # first level becomes reference
        "1"))) %>%  
  mutate(z.trial = scale(as.numeric(trial)),
         ageinyears = aged/365.25, 
         z.age = ageinyears - mean(ageinyears),
         z.sex = scale(as.numeric(sex))) %>% 
  mutate(item = gsub("_A.png", "", cue)) %>% 
  mutate(item = gsub("_B.png", "", item)) 

# test <- rep.data %>%
#   filter(valid != "drop") %>%
#   group_by(study) %>%
#   summarize(min_Age = min(agem))

# test <- rep.data %>% 
#   filter(valid != "drop") %>% 
#   group_by(study, condition) %>% 
#   summarize(N = length(subid))


```

```{r S1S2s3_participant_demographics, echo=FALSE, eval=T}

rep.age.table.data  <- rep.data %>% 
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid != "drop") %>%  # filter out dropped participants
  group_by(study) %>% 
  summarize(
    N = length(subid),
    female = sum(sex=="0"),
    Mean = mean(agem),
    Min = min(agem),
    Max = max(agem),
    SD = round(sd(agem), 2),
    N_daycare = length(subid[where == "daycare"]),
    N_lab = length(subid[where == "lab"]),
    N_home = length(subid[where == "home"]),
    N_hort = length(subid[where == "afterschoolcenter"]))

rep.age.table.data <- data.frame(rep.age.table.data, row.names = "study")

rep.drop.table.data  <- rep.data %>%
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid == "drop") %>%
  group_by(study) %>%
  summarize(
    N = length(subid),
    female = sum(sex=="0"),
    Mean = mean(agem),
    Min = min(agem),
    Max = max(agem),
    fail_in_fam = length(subid[drop == "fail_in_fam"]),
    quit_early = length(subid[drop == "quit_early"]),
    fussy_child = length(subid[drop == "fussy_child"]),
    language = length(subid[drop == "language"]),
    technical = length(subid[drop == "technical"]))

rep.drop.table.data <- data.frame(rep.drop.table.data, row.names = "study")

# Count trials by conditions
rep.s1.trials <- rep.S1.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

rep.s2.trials <- rep.S2.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

rep.s3.trials <- rep.S3.bayes.data %>% 
  group_by(condition) %>% 
  summarize(
    Trials = n(),                
    N = n_distinct(subid))

```

# Introduction
~~Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.~~

Preschoolers invent and comprehend iconic gestures spontaneously [@bohn2019young].

*Children's understanding of graphical representations*. 
~~Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.~~

*This Paper*. 
~~Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. For the first time, the studies contributing to this paper investigate children's understanding of xxx.~~

*Hypotheses*. ~~Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.~~

# Methods
All three studies presented here share the same methods and analyses. For convenience, common aspects of the procedure, participant recruiting and stimulus design are reported first before discussing the individual studies respectively.

## General Methods

### Setup and Data Collection
In order to trace the development of children's symbolic competence continuously across the preschool years, data collection aimed at testing two children per month of age between the third and the seventh birthday for a total 96 participants while euqally balancing male and female participants.  As children participated on the basis of availability and data collection was done by several experimenter teams visiting different institutions in parallel, the resulting final samples slightly exceed this preregistered minimum sample size. The final sample approximate an equal distribution of male and female participants and
while aligning with conventions in the field, by providing at least 24 participants per condition and year of age. 

All participants were recruited in **MASKED FOR REVIEW**, a medium-sized middle-European city, and came from a predominantly white population of middle to high income families. They were contacted via a database of participants for child development studies to which their parents had voluntarily signed up. Children were tested in day- and afterschoolcare for the most part, and occasionally in the lab or at home. The studies were reviewed and approved by an internal ethics committee at the **MASKED FOR REVIEW**. Data collection took place from June 2022 to February 2023. 

During test sessions, one child and an experimenter sat down together to play a picture-book-style hiding game presented on a touch-screen laptop. Verbal instructions were played back by the experimental script. Experimenters supervised children during data collection an assisted with a fixed set of verbal prompts when necessary. Test sessions always took place in a quiet separate room. See figure \@ref(fig:figure-setup) for an illustration of the setup.

(ref:testillustration-caption) Illustration of setup. Experimenters were sitting behind the children in order to not distract them from the task and supervised data collection.

```{r figure-setup, fig.cap = "(ref:testillustration-caption)", fig.align = "center", echo = FALSE}
knitr::include_graphics("../illustrations/Symlit_Rep_Setup_fromarrows.png", dpi = 108)

```

### Procedure
*Familiarization*. Experimenters invited children to join a hiding game and to follow the narration of the story. First, the presentation introduced a cartoon monkey. This character then placed two barriers on the bottom left and right side of the screen. After holding up a banana, one of the barriers was lifted, the banana was placed there and the barrier was lowered to conceal the banana. Children were now prompted to touch the hiding place and in doing so the barrier of their choice was lifted to reveal the banana if they chose correctly. Hence to succeed here, children solely had to remember where the item went and touch this part of the screen after a few seconds. The experimental script provided immediate feedback upon children's choice ("yes, great job!"; "No, that's not it. Let's try again!") during the familiarization. To ensure that children were familiar with the goal of the game and the touch interface, they first had to complete a set of four to eight familiarization trials with a success rate of 75%. In case a child did not reply correctly in three out of four trials, another four familiarization trials were provided. If the child was correct in six out of eight trials, she was included in the main sample. Children that did not succeed during familiarization were allowed to participate but their data was not submitted to analysis. These children are reported below as failing the familiarization phase.

*Test phase*. The main phase of the study commenced with announcing that the cartoon character had an idea for a new game. The narration conveyed that children were not allowed to see where the banana would be hidden, but that the monkey would help them find it. Hence, the cartoon character was established as a partner in a cooperative coordination game. The hiding sequence was identical to the familiarization phase, however the placement of the banana was concealed by a barrier over the lower half of the screen and the two hiding places displayed different graphical shapes in the same colour. The monkey then held up piece of paper and a pencil. Pencil movement and a short scribble sound indicated that the monkey was drawing something. Children were reminded that the monkey was going to help them. Children were now prompted with the phrase "Where is the banana?" and the monkey's drawing was placed in the center between the two barriers. The drawing now served as a cue to guide children's choice. In the most basic experimental condition in study one, each hiding places, for example, showed either a solid blue circle or square and the paper displayed a simple outline drawing of either shape. Here, the drawing was a direct representation of the target shape. Crucially, however, children received only neutral feedback upon making a choice ("Ah, thank you") and there was no reveal animation. The game simply continued with the next round in which two new hiding places with different shapes were displayed, and hiding sequence was repeated as before.

Except for the geometric shapes displayed on the hiding places and the respective drawing, the experimental representation was identical for all test trials. A single trial lasted roughly 30 to 60 seconds, depending on how swiftly children chose. Each study presented four different experimental conditions with four trials each in a blocked order for a maximum of 16 test trials. Children occasionally wished to stop before completing all trials, resulting in minor deviations of the total number of trials per condition that are submitted to analyses. Children that did not complete a minimum of eight test trials were not submitted to analysis and are reported below. The entire test session lasted about 12 minutes.

### Stimuli and Experimental Manipulations
Description of cues and targets and maybe how they were created. 

For an illustration of the stimuli and example presentations, please see supplementary materials sections XX and XX.  

### Data Handling and Analyses
Participant choices were recorded by the experimental script and directly coded as correct or incorrect. Exclusions of data were solely made on the level of participants with regard to the exclusion criteria reported above. The analyses modeled participants' binary choices to predict the probability of children interpreting the cues correctly and to model how this probability would change as a function of their age. Logistic Bayesian generalized linear mixed models (GLMM) fitted children's responses (0/1) as a function of their age, the experimental condition and an interaction between trial and condition. Trial and sex were included as fixed effects to be controlled for. Trial number was added as a random slope within subject. To evaluate the relevance of age and condition for children’s performance, a full model was compared with a reduced model lacking the interaction of age and task by using WAIC scores and weights (McElreath, 2016). Furthermore, model estimates were inspected for the different predictors (including their 95% Credible Interval (CrI)). In each study, the most simple condition was set as the reference level within conditions. All Bayesian models used default priors and were run in Stan (http://mc-stan.org/) via the function brm of the package brms (Bürkner, 2017).

To answer the main research question of when children performed above chance in any of the study's conditions, we use the models to predict the developmental trajectory (with 95% CrI) for each condition (expected values of the posterior predicted dist via fct fitted). The criterion for settling when children passed criterion as a group was the point at which the 95% CrI for a particular trajectory did no longer overlap with a midline demarcating the 50% chance level. 

To further explore the data, participants were binned according to their age in years. To test whether group-level performance was above chance in all experimental groups, we used two-tailed one-sample t-tests with the chance level set to .5. We provide Cohen's d as a standardized effect size for significance testing (computed via the function `cohensD`). 

- deviation from preregistration
- elpd_diff ist neu und zusätzlich
- most simple condition als reference ...warum
- bezeichnung output fitted function --> wie macht brms die confidence intervalle um die mittelwerte --> 
- "expected value of the posterior predicted distribution"

## Study 1

### Participants
A sample of `r rep.age.table.data["study1", "N"]` children (M = `r rep.age.table.data["study1", "Mean"]` months, SD = `r rep.age.table.data["study1", "SD"]` months, range `r rep.age.table.data["study1", "Min"]` - `r rep.age.table.data["study1", "Max"]` months; `r rep.age.table.data["study1", "female"]` female) participated in study 1. In addition, `r rep.drop.table.data["study1", "N"]` children (`r rep.drop.table.data["study1", "female"]` female) were tested but excluded from analysis for not succeeding during familiarization (N = `r rep.drop.table.data["study1", "fail_in_fam"]`), for not completing at least eight out of 16 test trials (N = `r rep.drop.table.data["study1", "quit_early"]`), or due to being fussy (N = `r rep.drop.table.data["study1", "fussy_child"]`). For `r rep.drop.table.data["study1", "language"]` children, experimenters only learned during testing that children were not fluent enough in German to participate as their families had only recently migrated. Finally, `r rep.drop.table.data["study1", "technical"]` children had to be excluded due to technical issues. For a graphical and tabular overview of participants and exclusions across all three studies presented here, please see Appendix A.

### Stimuli


### Analyses
A total of `r sum(rep.s1.trials$Trials)` trials (mean per condition = `r mean(rep.s1.trials$Trials)`, range: `r min(rep.s1.trials$Trials)` - `r max(rep.s1.trials$Trials)`) from `r rep.age.table.data["study1", "N"]` participants were submitted for analysis. The full model notation was $'correct~condition*z.age+z.trial+sex+(z.trial|subid)'$. In addition, a null model lacking the interaction of condition and age was fitted. 

```{r rep_s1_bayes, echo = FALSE, include=F, eval=F, results='asis'}

# NOTE: this is section is not evaluated to save time during knitting

# in prergistration we used the term "task" instead of "condition", same thing
# we have now decided to no scale sex to make interpretation more straightforward
# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S1.full.bm<-brm(correct~condition*z.age+z.trial+sex+(z.trial|subid), 
               data= rep.S1.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S1.full.bm <- add_criterion(S1.full.bm, c("loo", "waic"))

S1.null.bm<-brm(correct~condition+z.age+z.trial+sex+(z.trial|subid), 
               data= rep.S1.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S1.null.bm <- add_criterion(S1.null.bm, c("loo", "waic"))

### MODEL COMPARISON
S1.comp <- loo_compare(S1.null.bm, S1.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S1.weights <- model_weights(S1.null.bm, S1.full.bm, criterion = "waic") %>% as_tibble(rownames = "index")
# "significant" if elpd_diff > 2*se_diff (confer Sivula et al., 2020)

### LOO COMPARISON
### not reported, essentially identical
# S1.null.loo <- loo(S1.null.bm)
# S1.full.loo <- loo(S1.full.bm)
# S1.loo.comp <- loo_compare(S1.null.loo, S1.full.loo) %>%
#   as_tibble(rownames = "model")
# S1.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S1.full.bm, "../models/S1.full.bm.rds")
saveRDS(S1.null.bm, "../models/S1.null.bm.rds")
saveRDS(S1.comp, "../models/S1.comp.rds")
saveRDS(S1.weights, "../models/S1.weights.rds")

### item level model
# S1.item.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid)+ (z.age|item), 
#                data= rep.S1.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)


```

```{r rep_s1_inspect, echo = FALSE, include=F, eval=T, results='asis'}

S1.full.bm <- readRDS("../models/S1.full.bm.rds")
S1.null.bm <- readRDS("../models/S1.null.bm.rds")
S1.comp <- readRDS("../models/S1.comp.rds")
S1.weights <- readRDS("../models/S1.weights.rds")


### POSTERIOR PREDICTICE CHECKS
### Check plots ...they look good, as expected in binomial models
# pp_check(S1.full.bm)
# pp_check(S1.null.bm)
# pp_check(S1.full.bm, type = "bars")
# pp_check(S1.null.bm, type = "bars")

### EFFECTICE SAMPLE SIZES
### inspect rhat --> always 1 --> good
### inspect Bull_ESS --> always > 1000 --> good
# summary(S1.full.bm)
# summary(S1.null.bm)

# for reporting BULK_ESS
S1.full.coef <- summarise_draws(as_draws_df(S1.full.bm)) %>%
  filter(grepl("^b_", variable)) %>% 
  mutate(variable = gsub("b_", "", variable)) %>% 
  mutate(variable = gsub("condition", "", variable)) %>% 
  data.frame(row.names = "variable")

S1.null.coef <- summarise_draws(as_draws_df(S1.null.bm)) %>%
  filter(grepl("^b_", variable))

# mean(S1.full.coef_table$ess_bulk)
# min(S1.full.coef_table$ess_bulk)
# max(S1.full.coef_table$ess_bulk)
# 
# mean(S1.null.coef_table$ess_bulk)
# min(S1.null.coef_table$ess_bulk)
# max(S1.null.coef_table$ess_bulk)


```

```{r rep_S1_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T, warning = F, message=F}

# load model from rds
# S1.full.bm <- readRDS("../models/S1.full.bm.rds")
# table(rep.S1.bayes.data$condition)

nd1 <- tibble(z.age = rep(seq(from = min(rep.S1.bayes.data$z.age), to = max(rep.S1.bayes.data$z.age), length.out = 50),4),
             condition = c(rep("Representation",50), 
                           rep("Pars Pro Toto",50), 
                           rep("Complex Form Analogy",50), 
                           rep("Simple Form Analogy",50)), 
             # the four conditions in the data
             sex = rep(0,200),
             z.trial = rep(0,200))

# here we generate the fitted values based on the model
# the function fitted() takes in the model and the new dataset and generates a fitted values (inclucing upper and lower 95% CI) for every row in the dataset
# because our dataset ranges from min age to max age in the data, we get the prediction for the age range in the data 
# but we could also generate predictions for different ages of course
f1 <- fitted(S1.full.bm, 
             newdata = nd1, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd1)%>%
  mutate(age = z.age + mean(rep.S1.bayes.data$ageinyears)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d1 <- rep.S1.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) 

p1 <- f1 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

```

### Results

Posterior predictive checks for both full and null model indicated excellent fit of observed data and model predictions (see supplements for more information). Comparing the models using weights based on the Widely Applicable Information Criterion (WAIC) yielded `r round(S1.weights$value[2]*100,2)`% of the model weight for the full model, and `r round(S1.weights$value[1]*100,2)`% for the null model. Hence, the full model generally has a higher probability of making accurate predictions. Directly comparing the models' WAIC via expected log predictive density (ELPD) corroborates this (ELPD WAIC; full model = `r round(S1.comp$elpd_waic[1],2)`; null model = `r round(S1.comp$elpd_waic[2],2)`). The standard error of the difference in predictive accuracy (`r round(S1.comp$se_diff[2],2)`), however is lower than the difference itself (`r round(S1.comp$elpd_diff[2],2)`). While the full model slightly exceeds in predictive power, evidence in favor of this model is not decisive. A similar comparison via Leave-One-Out Cross-Validation (LOO) provided essentially the same results. In absence of conclusive evidence for either model, we report the results for the full model below in line with the preregistration.

Relative to the *Representation* condition, the *Simple Form Analogy* (beta = `r S1.full.coef["SimpleFormAnalogy", "mean"]`, 95% CI [`r S1.full.coef["SimpleFormAnalogy", "q5"]`, `r S1.full.coef["SimpleFormAnalogy", "q95"]`) and *Complex Form Analogy* (β = `r S1.full.coef["ComplexFormAnalogy", "mean"]`, 95% CI [`r S1.full.coef["ComplexFormAnalogy", "q5"]`, `r S1.full.coef["ComplexFormAnalogy", "q95"]`) have a considerably lower probability of correct responses. The *Pars Pro Toto* condition has no clear difference from the reference condition (β = `r S1.full.coef["ParsProToto", "mean"]`, 95% CI [`r S1.full.coef["ParsProToto", "q5"]`, `r S1.full.coef["ParsProToto", "q95"]`). Interaction terms between age and condition were not reliably different from zero. The developmental curves for each condition have essentially similar trajectories.

Finally, by tracing when the lower bound of the 95% CrI exceeds the chance level of 50%, it is possible to report when children's group level performance exceeds chance level and becomes robustly systematic in favor of the correct choice option. In study 1, children perform above chance in the *Representation* condition as early as `r p1$months[p1$condition == "Representation"]` months. Quickly after at XX months, children succed in the *Pars Pro Toto* condition. In the more abstract conditions *Simple Form Analogy* and Complex Form Analogy, preschoolers meet criterion at `r p1$months[p1$condition == "Simple Form Analogy"]` and `r p1$months[p1$condition == "Complex Form Analogy"]` months respectively. 

```{r S1_bayes_plot_no_facets, echo=FALSE, eval=T, warning = F, message=F}

# Plot without facetting

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

```{r S1_bayes_plot, echo=FALSE, eval=T, warning = F, message=F}

p1 <- f1 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

S1_plot <- ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

#
S1_plot

```

~~Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.~~

## Study 2


### Participants
A total of `r rep.age.table.data["study2", "N"]` three- to seven-year-old children (M = `r rep.age.table.data["study2", "Mean"]` months, SD = `r rep.age.table.data["study2", "SD"]` months, range `r rep.age.table.data["study2", "Min"]` - `r rep.age.table.data["study2", "Max"]` months; `r rep.age.table.data["study2", "female"]` female) participated. In addition, `r rep.drop.table.data["study2", "N"]` children (`r rep.drop.table.data["study2", "female"]` female) were tested but excluded from analysis for failing familiarization (N = `r rep.drop.table.data["study2", "fail_in_fam"]`), being fussy (N = `r rep.drop.table.data["study2", "fussy_child"]`), not being fluent in German (N = `r rep.drop.table.data["study2", "language"]`) or due to technical issues (N = `r rep.drop.table.data["study2", "technical"]`).

### Materials

### Data analysis
A total of `r sum(rep.s2.trials$Trials)` trials (mean per condition = `r mean(rep.s2.trials$Trials)`, range: `r min(rep.s2.trials$Trials)` - `r max(rep.s2.trials$Trials)`) from `r rep.age.table.data["study2", "N"]` participants were submitted for analysis. The full model notation was $'correct~condition*z.age+z.trial+sex+(z.trial|subid)'$. In addition, a null model lacking the interaction of condition and age was fitted. 



### Results

```{r S2_bayes_fullmodel, echo=FALSE, include=F, eval=F}


# S2.full.bm<-brm(correct~condition+z.age+(1|subid), 
#                data=rep.S2.bayes.data, 
#                family=bernoulli(),
#                chains = 4,
#                iter= 2000,
#                cores= 4)
# 

S2.null.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S2.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S2.null.bm <- add_criterion(S2.null.bm, c("loo", "waic"))

S2.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S2.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S2.full.bm <- add_criterion(S2.full.bm, c("loo", "waic"))

S2.comp <- loo_compare(S2.null.bm, S2.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S2.weights <- model_weights(S2.null.bm, S2.full.bm, criterion = "waic") %>% as_tibble(rownames = "index")

# 
# loo_compare(S2.null.bm, S2.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
# model_weights(S2.null.bm, S2.full.bm, criterion = "waic")

# Saving the model (to not rerun it every time)

### LOO COMPARISON
### not reported, essentially identical
# S2.null.loo <- loo(S2.null.bm)
# S2.full.loo <- loo(S2.full.bm)
# S2.loo.comp <- loo_compare(S2.null.loo, S2.full.loo) %>%
#   as_tibble(rownames = "model")
# S2.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S2.full.bm, "../models/S2.full.bm.rds")
saveRDS(S2.null.bm, "../models/S2.null.bm.rds")
saveRDS(S2.comp, "../models/S2.comp.rds")
saveRDS(S2.weights, "../models/S2.weights.rds")





```

```{r S2_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T}

# load model from saving rds
S2.full.bm <- readRDS("../models/S2.full.bm.rds")

nd2 <- tibble(z.age = rep(seq(from = min(rep.S2.bayes.data$z.age), 
                              to = max(rep.S2.bayes.data$z.age), 
                              length.out = 50),4),
             condition = c(rep("Relative Position",50), 
                           rep("Absolute Position",50), 
                           rep("Orientation of Feature",50), 
                           rep("Orientation of Object",50)), # the four conditions in the data
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f2 <- fitted(S2.full.bm, 
             newdata = nd2, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd2)%>%
  mutate(age = z.age + mean(rep.S2.bayes.data$ageinyears)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d2 <- rep.S2.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct))

```

```{r S2_bayes_plot, echo=FALSE, eval=T, warning=F, message=F}

p2 <- f2 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )



ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

```

```{r S2_mixbayes_plot, echo=FALSE, eval=T, warning=F, message=F}


p2 <- f2 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months"))
  )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

```

## Study 3
General note on the aim of the investigation

### Participants
A total of `r rep.age.table.data["study3", "N"]` three- to seven-year-old children (M = `r rep.age.table.data["study3", "Mean"]` months, SD = `r rep.age.table.data["study3", "SD"]` months, range `r rep.age.table.data["study3", "Min"]` - `r rep.age.table.data["study3", "Max"]` months; `r rep.age.table.data["study3", "female"]` female) participated. In addition, `r rep.drop.table.data["study3", "N"]` children (`r rep.drop.table.data["study3", "female"]` female) were tested but excluded for low performance during familiarization (N = `r rep.drop.table.data["study3", "fail_in_fam"]`), for not completing at least eight out of 16 test trials (N = `r rep.drop.table.data["study3", "quit_early"]`), or being fussy (N = `r rep.drop.table.data["study3", "fussy_child"]`). Another `r rep.drop.table.data["study3", "language"]`children were excluded due to language problems or technical issues (N = `r rep.drop.table.data["study3", "technical"]`).

### Materials

### Analysis
For study three, `r sum(rep.s3.trials$Trials)` trials (mean per condition = `r mean(rep.s3.trials$Trials)`, range: `r min(rep.s3.trials$Trials)` - `r max(rep.s3.trials$Trials)`) from `r rep.age.table.data["study3", "N"]` participants were submitted for analysis. Data were analyzed both with a full model ($'correct~condition*z.age+z.trial+sex+(z.trial|subid)'$) and a null model lacking the interaction of condition and age. 

### Results

```{r S3_bayes_fullmodel, echo=FALSE, include=F, eval=F}


S3.null.bm<-brm(correct~condition+z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S3.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S3.null.bm <- add_criterion(S3.null.bm, c("loo", "waic"))

S3.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S3.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))

S3.comp <- loo_compare(S3.null.bm, S3.full.bm, criterion = "waic")%>%as_tibble(rownames = "index")
S3.weights <- model_weights(S3.null.bm, S3.full.bm, criterion = "waic") %>% as_tibble(rownames = "index")

### LOO COMPARISON
### not reported, essentially identical
# S2.null.loo <- loo(S2.null.bm)
# S2.full.loo <- loo(S2.full.bm)
# S2.loo.comp <- loo_compare(S2.null.loo, S2.full.loo) %>%
#   as_tibble(rownames = "model")
# S2.loo.comp

# Saving the model (to not rerun it every time)
saveRDS(S3.full.bm, "../models/S3.full.bm.rds")
saveRDS(S3.null.bm, "../models/S3.null.bm.rds")
saveRDS(S3.comp, "../models/S3.comp.rds")
saveRDS(S3.weights, "../models/S3.weights.rds")

# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)
# 
# S3.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
#                 data= rep.S3.bayes.data, 
#                 family=bernoulli(),
#                 chains = 4,
#                 iter= 2000,
#                 cores= 4)
# 
# S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))
# 
# # Saving the model (to not rerun it every time)
# saveRDS(S3.full.bm, "../models/S3.full.bm.rds")

```

```{r S3_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T, warning=F, message=F}

# load model from saving rds
S3.full.bm <- readRDS("../models/S3.full.bm.rds")

nd3 <- tibble(z.age = rep(seq(from = min(rep.S3.bayes.data$z.age), 
                              to = max(rep.S3.bayes.data$z.age), 
                              length.out = 50),4),
             condition = c(rep("Number of Object",50), 
                           rep("Number of Feature",50), 
                           rep("Size of Object",50), 
                           rep("Size of Feature",50)),
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f3 <- fitted(S3.full.bm, 
             newdata = nd3, 
             re_formula = NA) %>% 
  as_tibble() %>%
  bind_cols(nd3)%>%
  mutate(age = z.age + mean(rep.S3.bayes.data$ageinyears)) 


# summarize the data to include them in the plot later on
d3 <- rep.S3.bayes.data%>%
  group_by(subid, ageinyears, condition)%>%
  summarise(mean = mean(correct)) 

```

```{r S3_bayes_plot, echo=FALSE, eval=T, warning=F, message=F}

# Plot without facetting
p3 <- f3 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months")))

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")




```

```{r S3_mixbayes_plot, echo=FALSE, eval=T, warning=F, message=F}

p3 <- f3 %>%
  mutate(age = age * 365.25)%>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/365.25, 2),
    monthlabels = as.character(paste(months, "months")))

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = ageinyears, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/365.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/365.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/365.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

```{r summaryresults,  echo=FALSE, eval=T, warning=F, message=F}

p_all <- rbind(p1,p2,p3)
p_all %>% arrange(months)

```


# Additional Analyses

possible add-ons
- a model including all conditions
- comparing difficulty across items and tasks
- evaluating manipulations such as complex/simple; 
- reaction time analyses

Additional Analyses:

object vs feature
- orfe vs orob
- sife vs siob
- nufe vs nuob

round vs angular
- Study One Study1 - cue A = rund, cue B eckig ...if one of them is easier

Reaction Times
just reaction times and perc correct across aged


# General Discussion

Overview

Main Finding

Strengths and Implications

Limitations

# Conclusion
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::







\newpage

# (APPENDIX) Appendix {-}

```{r child = "appendix_a_participants.Rmd"}
```

```{r child = "appendix_b_stimuli.Rmd"}
```

```{r child = "appendix_c_descriptives.Rmd"}
```

```{r child = "appendix_d_diagnostics.Rmd"}
```

```{r child = "appendix_e_additional.Rmd"}
```

