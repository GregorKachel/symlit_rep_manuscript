---
title             : "Young children’s spontaneous comprehension of symbol-object-relationships in the graphic domain"
shorttitle        : "Comprehension of symbol-object-relationships"

author: 
  - name          : "Gregor Kachel"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Universitätsallee 1, C1.008a, 21335 Lüneburg"
    email         : "gregor.kachel@leuphana.de"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Funding Acquisition"
      - "Project Administration"
      - "Investigation"
      - "Methodology"
      - "Data Curation"
      - "Formal Analysis"
      - "Visualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Daniel Haun"
    affiliation   : "2"
    role:
      - "Resources"
      - "Writing - Review & Editing"
  - name          : "Manuel Bohn"
    affiliation   : "1"
    role:
      - "Methodology"
      - "Software"
      - "Formal Analysis"
      - "Validation"
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Leuphana University"
  - id            : "2"
    institution   : "Max-Planck-Institute for Evolutionary Anthropology"


authornote: |
    *Ethics, consent and conflict of interest*: This study confirms with recognized standards (e.g. the Declaration of Helsinki) and was approved by an internal ethics committee at the Max-Planck-Institute for Evolutionary Anthropology. Informed consent has been obtained from all participants. The authors declare no conflict of interest. 
    
    *Acknowledgments*: We are thankful to Susanne Mauritz for her help in the organization of the study and to Valerie Jurgenson and Cynthia Pones for help with data collection. We would like to thank Anne Deiglmayr for hosting this project in her research group and for her continuous support. Finally, we are very thankful to all parents and children participating in the study. Gregor Kachel was supported by the German Research Foundation (Deutsche Forschungsgemeinschaft) under project number 429220405.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  One or two sentences to put the results into a more **general context**.
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline. !Abstract must be less then 120words!
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "graphical representation, iconicity, analogy, symbol, communication, emerging literacy"
wordcount         : "Child Development Max 40 pages // PNAS 1,500–2,000 words"

bibliography      : ["library.bib"]

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("library.bib")

# Loading packages 
# NOTE: this will install these packages on your machine in case they are missing

# General
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
if (!require(lsr)) install.packages('lsr'); library(lsr) # Analysis, Cohen's D
if (!require(ggthemes)) install.packages('ggthemes'); library(ggthemes) # for tufte boxplots

# bayes packages
if (!require(brms)) install.packages('brms'); library(brms) # 
if (!require(tidybayes)) install.packages('tidybayes'); library(tidybayes) # 
if (!require(HDInterval)) install.packages('HDInterval'); library(HDInterval) # 

# Troubleshooting Knitting Document
# might be required for knitting manuscript
# install.packages('tinytex')
# tinytex::install_tinytex()
# 
# tinytex::tlmgr_update()
# tinytex::reinstall_tinytex()

```

```{r analysis-preferences, include = FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

*General notes Citing stuff*. You have to make sure that the respective reference in included in the bib-file. I would also suggest to have two additional folders in the root, namely (1) papers to cite - where we can dumb pdfs, and (2) papers_cited. Whenever you are adding a new reference please put the citation in bibtex, name the pdf accorind to the bibtext id and add the pdf to the papers_cited folder. And this is how to cite something in markdown: Preschoolers invent and comprehend iconic gestures spontaneously [@bohn2019young].

*Children's understanding of graphical representations*. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

*This Paper*. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. For the first time, the studies contributing to this paper investigate children's understanding of xxx.

*Hypotheses*. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

# Study 1

## Methods

```{r rep_read_data, include = FALSE}

# Full data set including all participants (i.e. including dropped participants)
rep.data <- readRDS("./data/symlitrep_final_data.rds")


 # $ study          : Factor w/ 3 levels --> Study1, Study2, Study3
 # $ title          : Factor w/ 3 levels --> Name/Theme of the Study
 # $ condition      : Factor w/ 12 levels --> Name of the condition i.e. experimental manipulation
 # $ cond           : Factor w/ 12 levels --> Name of the condition in short form
 # $ subid          : Factor w/ 364 levels --> Subjet ID
 # $ sex            : Factor w/ 2 levels "0","1": --> Participants' sex; 1 = male
 # $ agey           : num [1:7146] total age in years
 # $ agem           : num [1:7146] total age in months 
 # $ aged           : num [1:7146] total age in days
 # $ valid          : Factor w/ 3 levels --> Status of Participants
      # "valid"= main sample
      # "drop" = excluded participants
      # "oversampling" = data collected after reaching the minimum of 96 participants per study
 # $ drop           : Factor w/ 7 levels "fail_in_fam",..: --> Reasons for Participant exclusions
      # fail_in_fam  --> did not meet criterion in familiarisation phase
      # fussy_child  --> child was fussy or uncooperative, lost interest in participating   
      # language     --> child did not understand instructions due to not speaking German fluently enough  
      # oversampling --> Not a drop per se: participants tested after reaching minimum of participants  
      # quit_early   --> Children that quit early and did not contribute at least 8 test trials 
      # technical    --> technical problems; i.e. script for presenting experiment crashed
 # $ trial          : Factor w/ 17 levels NUmbers 1-16 for test trials; "fam" for familiarisation trials
 # $ correct        : int [1:7146] correct choice = 1; incorrect = 0
 # $ rt             : int [1:7146] reaction time in ms
 # $ experimenter   : Factor w/ 6 levels --> ID of the experimenter; E1 - E6
 # $ where          : Factor w/ 4 levels 
      # afterschoolcenter --> after school care; testing in the early afternoon
      # daycare --> testing in kindergartens, prior to lunch
      # home --> testing during visits at home; usually in the afternoon
      # lab --> children were tested when visiting the lab; usually in the afternoon
 # $ eselectfam     : Factor w/ 2 levels "0","1" 
      # experimenter occasionally selected choices based on child's pointing during familiarisation traisl
 # $ eselectmain    : Factor w/ 2 levels "0","1"
      # experimenter occasionally selected choices based on child's pointing during test trails
 # $ leftObject     : Factor w/ 99 levels "abpo_tar_1_A.png" 
      # --> stimulus item displayed on the left side of the screen as target/distractor
 # $ rightObject    : Factor w/ 99 levels "abpo_tar_1_A.png"
      # --> stimulus item displayed on the right side of the screen as target/distractor
 # $ cue            : Factor w/ 98 levels "abpo_cue_1_A.png"
      # --> stimulus item displayed in the middle of the screen as a cue
 # $ target_position: Factor w/ 2 levels "left","right": 
      # side on which the target (i.e. correct choice) was presented
 # $ item           : Factor w/ 4 levels "1","2","3","4":
      # number of stimulus item in the respective condition
 # $ target_shape   : Factor w/ 2 levels "A","B":
      # target stimulus shape in the respective condition
 # $ pick           : Factor w/ 2 levels "
      # side of children's choice (left/right) 
 
```

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study [@simmons201221]. Supplementary materials document all pilots that were run and the specific conclusions we drew from them during the development of the study. Both supplements and main article are fully reproducible manuscripts [@R-papaja] providing all data and analyses. 

### Participants
```{r S1S2s3 participant demographics, echo=FALSE, eval=FALSE}

rep.age.table.data  <- rep.data %>% 
  distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
  filter(valid != "drop") %>%  # filter out dropped participants
  group_by(study) %>% 
  summarize(
    N = length(subid),
    female = sum(sex=="0"),
    Mean = mean(agem),
    Min = min(agem),
    Max = max(agem),
    SD = round(sd(agem), 2))
# 
# drop.table.data  <- data %>% 
#   distinct(subid, .keep_all = TRUE) %>% # select only one line per participant
#   filter(valid == "drop") %>%  # filter out dropped participants
#   group_by(study) %>% 
#   summarize(
#     N = length(subid),
#     female = sum(sex=="0"),
#     Mean = mean(agem),
#     Min = min(agem),
#     Max = max(agem),
#     SD = round(sd(agem), 2))

# convert first column into row names
age.table.data <- data.frame(age.table.data, row.names = "study")


#  A total of `r age.table.data["study1", "N"]` two- to four-year-old children (M = `r age.table.data["study1", "Mean"]` months, SD = `r age.table.data["study1", "SD"]` months, range `r age.table.data["study1", "Min"]` - `r age.table.data["study1", "Max"]` months; `r age.table.data["study1", "female"]` female) participated in the study (see Figure\ \@ref(fig:S1ArrowsProgressDataCollectionPlot) for an overview of the age-distribution). 

```

We collected age as a continues predictor aiming to test two children per month of age between the third and seventh birthday.

All participants were recruited in **MASKED FOR REVIEW**, a medium-sized middle-European city, and came from a predominantly white population of middle to high income families. They were contacted via a database of participants for child development studies to which their parents had voluntarily signed up. Appointments were made on the basis of parents’ and children’s availability. The study was reviewed and approved by an internal ethics committee at the **MASKED FOR REVIEW**. 

ALL STUDIES Data collection took place from June 2022 to February 2023. 

In addition, XX children were tested but not submitted to the final sample for not succeeding in familiarization trials (N = XX), for not completing at least eight out of 16 test trials (N = XX), or due to being fussy (N = XX). All excluded children were younger than 36 months of age.


### Procedure and Setup
Children were visited in-person at their daycares. Daycares provided a separate room where experimenters (E) and children watched the presentation of a picture-book like hiding game on screen while sitting at their side. See figure \@ref(fig:figure-setup) for an illustration of the setup.

(ref:testillustration-caption) Illustration of setup.

```{r figure-setup, fig.cap = "(ref:testillustration-caption)", fig.align = "center", echo = FALSE}
knitr::include_graphics("./illustrations/Symlit_Rep_Setup.png", dpi = 108)
```

*Familiarization*. E introduced an agent, namely a cartoon monkey, and familiarized children with the framing of the task. The monkey placed two small cups at the bottom of the screen. Next, the cups were lifted and the monkey dropped a banana under one of them. The cups were lowered again to hide the banana. Hence, children saw an item being hidden in plain sight and were solely required to remember its place for a minimal amount of time  before being asked "Where is the banana?". Children were required to point at the correct hiding place. In the familiarization phase, children received immediate feedback from the experimenter ("Well done!" / "hmm, lets go again!") while the hiding place of the banana was revealed. Children are expected to succeed in at least 4 familiarization trials in a row in order to move to the main test. Familiarization would continue for a minimum of four and a maximum of eight trials. The familiarization ensured that all participants were familiar with the aim of the game and that E was able to read participants' responses.

*Test phase*.The main phase of the study commenced with E announcing that the cartoon character had an idea for a new game. E explains that they must not see where the banana is hidden. The hiding sequence is identical to the familiarization phase, however the placement of the banana is covered by a wood fence over the lower half of the screen. Next, the monkey holds up geometric shape, namely a circle in the *marker condition* and an equilateral triangle in the *arrow condition*. E narrates "Coco is going to help you find the banana. In the arrow condition, the monkey places the triangle in a central position pointing to either the left or right target. In the marker condition, the monkey places the circle directly on the left or right target. After the placement, children are asked "where is the banana?". The hiding place is not revealed and children do not receive feedback in test trials. E acknowledges their choices by thanking them in a neutral tone and moves on to the next trial.

Except for the geometric shapes and their placement, the presentations in both conditions were identical. A single trial lasted 20 to 30 seconds. Children were presented with a maximum of 16 test trials half of which in either condition. In order to be submitted to the analyses participants had to complete at least eight valid test trials (see coding below).The entire test sessions lasted about 15 minutes. See figure XXX for an illustration of the setup.

### Materials
Description of cues and targets and maybe how they were created. For an illustration of the stimuli and example presentations, please see supplementary materials sections XX and XX.  

### Data analysis
Bayesian models were run in Stan (http://mc-stan.org/) and implemented via the function brm of the package brms (Bürkner, 2017). We used logistic Bayesian generalized linear mixed models (GLMM) to fit children's responses (0/1) as a function of their absolute age in days, condition (rep, pars, fsim, fcom) and an interaction between trial and task. We use default priors and include trial and sex as fixed effects to be controlled for. Trial number will be added as a random slope within subject.

The full model notation was: $'correct~condition*z.age+z.trial+z.sex+(z.trial|subid)'$
•	correct: correct choice (0/1)
•	z.age: age in days, centered to a mean of 0 
•	z.trial: trial number, scaled
•	z.sex: participants' sex (male/female), scaled

The analysis modeled participants binary choices to predict the probability of children interpreting the cues correctly and model how this probability will change as a function of their absolute age in days. We used the model to predict the
developmental trajectory (with 95% CrI) for each task type. The criterion for settling when children perform above chance with either type of stimuli is the point at which the 95% CrI for a particular trajectory does no longer overlap with a midline demarcating the 50% chance level.

For our main analyses, we used logistic Bayesian generalized linear mixed models (GLMM) to fit children’s responses (0/1) as a function of their absolute age in days, task (arrow, marker) and an interaction between trial and task. We used default priors and included trial and sex as fixed effects to be controlled for. Trial number was added as a random slope within subject. The full model notation was $'correct ~ task*z.age +z.trial +z.sex +(z.trial|id)'$.

The analysis models participants binary choices to predict the probability of children interpreting the cues correctly and model how this probability will change as a function of their absolute age in days. In order to evaluate the relevance of age and task type for children’s performance, we compared a full model as specified above with a reduced model lacking the interaction of age and task by using WAIC scores and weights (McElreath, 2016). Furthermore, we inspected the model estimates for the different predictors (including their 95% Credible Interval (CrI)). To answer our main research question of when children perform above chance in a task, we use the model to predict the developmental trajectory (with 95% CrI) for each task type. The criterion for settling when children perform above chance is the point at which the  95% CrI for a particular trajectory does no longer overlap with a midline demarcating the 50% chance level. 

To further explore our data, we also binned participants in age-groups (three-, and four-year-olds). To test whether group-level performance was above chance in all experimental groups, we used two-tailed one-sample t-tests with the chance level set to .5. We provide Cohen's d as a standardized effect size for significance testing (computed via the function `cohensD`). Additionally, each participant's data was also submitted to a binomial test to determine whether their performance was above chance on an individual level. 

### Results

```{r rep_s1_bayes_predata, echo = FALSE, include=F, eval=T, results='asis'}

# prepare data 
rep.S1.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study1") %>% # in study one
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, correct, trial) %>%
  mutate(z.trial = scale(as.numeric(trial)),
         z.age = aged - mean(aged),
         z.sex = scale(as.numeric(sex)))

# # clean data set? 
# str(rep.S1.bayes.data)
# sapply(rep.S1.bayes.data, function(x) sum(is.na(x)))


```

```{r rep_s1_bayes, echo = FALSE, include=F, eval=F, results='asis'}

# this is section is not evaluated to save time during knitting

# in prergistration we used the term "task" instead of "condition", same thing
# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S1.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data= rep.S1.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S1.full.bm <- add_criterion(S1.full.bm, c("loo", "waic"))

# Saving the model (to not rerun it every time)
saveRDS(S1.full.bm, "./models/S1.full.bm.rds")

```

```{r rep_S1_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T}

# load model from rds
S1.full.bm <- readRDS("./models/S1.full.bm.rds")
# table(rep.S1.bayes.data$condition)

nd1 <- tibble(z.age = rep(seq(from = min(rep.S1.bayes.data$z.age), to = max(rep.S1.bayes.data$z.age), length.out = 50),4),
             condition = c(rep("Representation",50), 
                           rep("Pars Pro Toto",50), 
                           rep("Complex Form Analogy",50), 
                           rep("Simple Form Analogy",50)), 
             # the four conditions in the data
             z.sex = rep(0,200),
             z.trial = rep(0,200))

# here we generate the fitted values based on the model
# the function fitted() takes in the model and the new dataset and generates a fitted values (inclucing upper and lower 95% CI) for every row in the dataset
# because our dataset ranges from min age to max age in the data, we get the prediction for the age range in the data 
# but we could also generate predictions for different ages of course
f1 <- fitted(S1.full.bm, 
             newdata = nd1, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd1)%>%
  mutate(age = z.age + mean(rep.S1.bayes.data$aged)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d1 <- rep.S1.bayes.data%>%
  group_by(subid, aged, condition)%>%
  summarise(mean = mean(correct)) 


```

```{r S1_bayes_plot_no_facets, echo=FALSE, eval=T, warning = F}

# Alternative Plot without facetting

p1 <- f1 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

```{r S1_bayes_plot, echo=FALSE, eval=T, warning = F}

p1 <- f1 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

S1_plot <- ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d1, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f1, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p1, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p1, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p1, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

S1_plot

```

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

# Study 2

## Methods
We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study [@simmons201221]. Supplementary materials document all pilots that were run and the specific conclusions we drew from them during the development of the study. Both supplements and main article are fully reproducible manuscripts [@R-papaja] providing all data and analyses. 

### Participants

### Procedure and Setup

### Materials

### Data analysis

### Results
```{r s2_bayes_prep_data, echo = FALSE, include=T, eval=T, results='asis'}

# prepare data 
rep.S2.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study2") %>% # in study one
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, correct, trial) %>%
  mutate(z.trial = scale(as.numeric(trial)),
         z.age = aged - mean(aged),
         z.sex = scale(as.numeric(sex)))

# # clean data set?
# str(rep.S1.bayes.data)
# sapply(rep.S1.bayes.data, function(x) sum(is.na(x)))


```

```{r S2_bayes_fullmodel, echo=FALSE, include=F, eval=F}

S2.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data=rep.S2.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S2.full.bm <- add_criterion(S2.full.bm, c("loo", "waic"))

# Saving the model (to not rerun it every time)
saveRDS(S2.full.bm, "./models/S2.full.bm.rds")

```

```{r S2_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T}

# load model from saving rds
S2.full.bm <- readRDS("./models/S2.full.bm.rds")

nd2 <- tibble(z.age = rep(seq(from = min(S2.bayes.data$z.age), to = max(S2.bayes.data$z.age), length.out = 50),4),
             condition = c(rep("repo",50), 
                           rep("abpo",50), 
                           rep("orfe",50), 
                           rep("orob",50)), # the four conditions in the data
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f2 <- fitted(S2.full.bm, 
             newdata = nd2, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd2)%>%
  mutate(age = z.age + mean(S2.bayes.data$aged)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d2 <- S2.bayes.data%>%
  group_by(subid, aged, condition)%>%
  summarise(mean = mean(correct))

```

```{r S2_bayes_plot, echo=FALSE, eval=T}


p2 <- f2 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")


# 
# S2_plot <- ggplot()+
#   geom_hline(yintercept = .5, lty = 2, alpha = .75)+
#   geom_point(data = d2, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+ 
#   geom_smooth(data = f2, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), stat = "identity", alpha = .4)+
#  # geom_vline(xintercept = round(f1$Q2.5=0.5), colour = "black", size = .5, alpha = .4) +
#   theme_minimal()+
#   scale_color_ptol(name = "condition")+
#   scale_fill_ptol(name = "condition")+
#   facet_grid(~condition)+
#   labs(x = "Age", y="Proportion Correct")+
#   ylim(0,1)+
#   xlim(3,7)+
#   theme(legend.position = "bottom")
# S2_plot

```

```{r S2_mixbayes_plot, echo=FALSE, eval=T}

p2 <- f2 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d2, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f2, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p2, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p2, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p2, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  #facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")

```


# Study 3

## Methods

### Participants

### Procedure and Setup

### Materials

### Data analysis
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy

### Results
```{r s3_bayes_prep_data, echo = FALSE, include=T, eval=T, results='asis'}

# prepare data 
rep.S3.bayes.data  <- rep.data %>%
  filter(valid != "drop") %>% # valid participants only 
  filter(study == "study2") %>% # in study one
  filter(trial != "fam") %>% 
  select(condition, subid, sex, aged, correct, trial) %>%
  mutate(z.trial = scale(as.numeric(trial)),
         z.age = aged - mean(aged),
         z.sex = scale(as.numeric(sex)))
# 
# # clean data set?
# str(rep.S1.bayes.data)
# sapply(rep.S3.bayes.data, function(x) sum(is.na(x)))

```

```{r S3_bayes_fullmodel, echo=FALSE, include=F, eval=F}

# preregistered: correct ~ task*z.age +z.trial +z.sex +(z.trial|id)

S3.full.bm<-brm(correct~condition*z.age+z.trial+z.sex+(z.trial|subid), 
               data=rep.S3.bayes.data, 
               family=bernoulli(),
               chains = 4,
               iter= 5000,
               cores= 4)

S3.full.bm <- add_criterion(S3.full.bm, c("loo", "waic"))

# Saving the model (to not rerun it every time)
saveRDS(S3.full.bm, "./models/S3.full.bm.rds")

```

```{r S3_bayes_fullmodel_prep_prepplotting, echo=FALSE, eval=T}

# load model from saving rds
S3.full.bm <- readRDS("./models/S3.full.bm.rds")

nd3 <- tibble(z.age = rep(seq(from = min(S3.bayes.data$z.age), to = max(S3.bayes.data$z.age), length.out = 50),4),
             condition = c(rep("nuob",50), 
                           rep("nufe",50), 
                           rep("siob",50), 
                           rep("sife",50)), # the four conditions in the data
             z.sex = rep(0,200),
             z.trial = rep(0,200))

f3 <- fitted(S3.full.bm, 
             newdata = nd3, 
             re_formula = NA) %>% 
  # this tells the function to ignore the random effects - in theory, we could generate predictions for specific individuals
  as_tibble() %>%
  bind_cols(nd3)%>%
  mutate(age = z.age + mean(S3.bayes.data$aged)) # convert age back to the original scale by adding the mean of the data


# summarize the data to include them in the plot later on
d3 <- S3.bayes.data%>%
  group_by(subid, aged, condition)%>%
  summarise(mean = mean(correct))

```

```{r S3_bayes_plot, echo=FALSE, eval=T}

# S3_plot <- ggplot()+
#   geom_hline(yintercept = .5, lty = 2, alpha = .75)+
#   geom_point(data = d3, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+ 
#   geom_smooth(data = f3, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), stat = "identity", alpha = .4)+
#  # geom_vline(xintercept = round(f1$Q2.5=0.5), colour = "black", size = .5, alpha = .4) +
#   theme_minimal()+
#   scale_color_ptol(name = "condition")+
#   scale_fill_ptol(name = "condition")+
#   facet_grid(~condition)+
#   labs(x = "Age", y="Proportion Correct")+
#   ylim(0,1)+
#   xlim(3,7)+
#   theme(legend.position = "bottom")
# S3_plot

p3 <- f3 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  facet_grid(~condition)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")


```

```{r S3_mixbayes_plot, echo=FALSE, eval=T}
# 
# S3_mixplot <- ggplot()+
#   geom_hline(yintercept = .5, lty = 2, alpha = .75)+
#   geom_point(data = d3, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+ 
#   geom_smooth(data = f3, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), stat = "identity", alpha = .4)+
#  # geom_vline(xintercept = round(f1$Q2.5=0.5), colour = "black", size = .5, alpha = .4) +
#   theme_minimal()+
#   scale_color_ptol(name = "condition")+
#   scale_fill_ptol(name = "condition")+
#   #facet_grid(~condition)+
#   labs(x = "Age", y="Proportion Correct")+
#   ylim(0,1)+
#   xlim(3,7)+
#   theme(legend.position = "bottom")
# S3_mixplot


p3 <- f3 %>%
  group_by(condition)%>%
  summarise(
    Q2.5_closest_to.5 = Q2.5[which.min(abs(Q2.5-.5))],
    estimate_closest_to.5 = Estimate[which.min(abs(Q2.5-.5))],
    days = age[which.min(abs(Q2.5-.5))],
    months = round(days/30.5),
    years = round(days/355.25, 2),
    monthlabels = as.character(paste(months, "months"))
    )

ggplot()+
  geom_hline(yintercept = .5, lty = 2, alpha = .75)+
  geom_point(data = d3, aes(x = aged/365, y = mean, col = condition), alpha = .5, shape = 1)+
  geom_smooth(data = f3, aes(x = age/365, y = Estimate, ymin = Q2.5, ymax = Q97.5, fill =condition, col = condition), 
              stat = "identity", alpha = .25)+
  geom_point(data=p3, aes(x = days/364.25, y = .5, fill = condition, col = condition), stat = "identity", size=3)+
  geom_text(data=p3, aes(label = months, x = days/364.25, y = .24, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  geom_text(data=p3, aes(label = "months", x = days/364.25, y = .38, fill = condition, col = condition), angle=90, size = 4, parse=T)+
  theme_minimal()+
  scale_color_ptol(name = "condition")+
  scale_fill_ptol(name = "condition")+
  # facet_grid(~study)+
  labs(x = "Age", y="Proportion correct")+
  ylim(0,1)+
  xlim(3,7)+
  theme(legend.position = "bottom")



```

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

## Additional Analyses

possible add-ons
- a model including all conditions
- comparing difficulty across items and tasks
- evaluating manipulations such as complex/simple; 
- reaction time analyses

# General Discussion
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

# Conclusion
Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
